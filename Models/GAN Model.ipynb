{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Generating Music Using GAN</center>\n",
    "\n",
    "This workbook will implement modified code from [this](https://github.com/corynguyen19/midi-lstm-gan) GitHub repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function, division\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from music21 import converter, instrument, note, chord, stream, duration\n",
    "from music21 import duration as D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, CuDNNLSTM, Bidirectional\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import argmax\n",
    "from tensorflow import map_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Cleaning the Data\n",
    "\n",
    "First, I will load all the notes from the midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ../Pokemon GSC MIDIs\\Pokemon Gold, Silver, Crystal - Cinnabar Island (HGSS Version).mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon Gold, Silver, Crystal - S.S. Aqua .mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Azalea TownBlackthorn City.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Bicycle.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Bug Catching Contest.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Burned Tower.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Champion Battle.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Cherrygrove CityMahogany Town.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Dance Theatre.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Dark Cave.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Dragons Den.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Ecruteak CityCianwood City.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Girl Trainer Confrontation.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Goldenrod City.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Gym Leader Defeated.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Gym.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Indigo Plateau.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Johto Gym Leader Battle.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Johto Wild Pokemon Battle.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Kanto Gym Leader Battle.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Lavender Town.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Menu.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - National Park.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - New Bark Town.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Olivine Lighthouse.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Pokemon Lullaby.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Pokemon March.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Professor Elms Lab.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Professor Oaks Theme.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Rival Battle.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 27.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 29.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 32.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 38.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 42.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Saffron City.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Show Me Around.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Sprout Tower.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Staff Credits.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Surf.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Team RocketRadio Tower Takeover.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Tin Tower.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Title.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Union Cave.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Victory Road.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Violet CityOlivine City.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Cerulean City.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Cinnabar Island.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Game Corner.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Indigo Plateau.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Instructions.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Lyras Theme.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - New Bark Town.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Pokemaniac Encounter.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Pokemon Center.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - PokeWalker Synchronisation.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Route 4748.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Safari Zone Gate.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Team Rocket Hideout.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Title.mid\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Viridian Forest.mid\n"
     ]
    }
   ],
   "source": [
    "def get_notes(path):\n",
    "    \"\"\"\n",
    "        Gets all notes and chords from midi files\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(path + \"*.mid\"):        \n",
    "        song = []\n",
    "        midi = converter.parse(file)\n",
    "        \n",
    "        print(\"Parsing %s\" % file)\n",
    "        \n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                song.append([str(element.pitch), element.offset, element.duration])\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                song_note = '.'.join(str(n) for n in element.normalOrder)\n",
    "                song.append([song_note, element.offset, element.duration])\n",
    "        notes.append(song)\n",
    "\n",
    "    return notes\n",
    "\n",
    "def get_notes_with_key(path, filter_key, mode):\n",
    "    \"\"\"\n",
    "        Gets all notes and chords from midi files\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(path + \"*.mid\"):        \n",
    "        song = []\n",
    "        midi = converter.parse(file)\n",
    "        \n",
    "#         Only use music of the same key\n",
    "        key = midi.analyze('key')\n",
    "        if(mode==0):\n",
    "            key_string = str(key.tonic.name)\n",
    "        elif(mode==1):\n",
    "            key_string = str(key.mode)\n",
    "        else:\n",
    "            key_string = str(key.tonic.name + key.mode)\n",
    "            \n",
    "        if(key_string==filter_key):\n",
    "            print(\"Parsing %s\" % file)\n",
    "\n",
    "            notes_to_parse = None\n",
    "\n",
    "            try: # file has instrument parts\n",
    "                s2 = instrument.partitionByInstrument(midi)\n",
    "                notes_to_parse = s2.parts[0].recurse() \n",
    "            except: # file has notes in a flat structure\n",
    "                notes_to_parse = midi.flat.notes\n",
    "\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    song.append([str(element.pitch), element.offset, element.duration])\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    song_note = '.'.join(str(n) for n in element.normalOrder)\n",
    "                    song.append([song_note, element.offset, element.duration])\n",
    "            notes.append(song)\n",
    "\n",
    "    return notes\n",
    "\n",
    "# def get_notes_with_key(path, filter_key, mode):\n",
    "#     \"\"\"\n",
    "#         Gets all notes and chords from midi files where the key matches the string input\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         path : str\n",
    "#             The path to the file\n",
    "#         filter_key : str\n",
    "#             The string to filter the key on\n",
    "#         mode : int\n",
    "#             The type of key used where:\n",
    "#                 0 - key\n",
    "#                 1 - major/minor\n",
    "#                 else - key and major/minor\n",
    "#     \"\"\"\n",
    "#     notes = []\n",
    "\n",
    "#     for file in glob.glob(path + \"*.mid\"):        \n",
    "#         song = []\n",
    "#         midi = converter.parse(file)\n",
    "        \n",
    "#         # Only use music of the same key\n",
    "#         key = midi.analyze('key')\n",
    "#         if(mode==0):\n",
    "#             key_string = str(key.tonic.name)\n",
    "#         elif(mode==1):\n",
    "#             key_string = str(key.mode)\n",
    "#         else:\n",
    "#             key_string = str(key.tonic.name + key.mode)\n",
    "            \n",
    "#         if(key_string==filter_key):\n",
    "#             print(\"Parsing %s\" % file)\n",
    "#             notes_to_parse = None\n",
    "\n",
    "#             try: # file has instrument parts\n",
    "#                 s2 = instrument.partitionByInstrument(midi)\n",
    "#                 notes_to_parse = s2.parts[0].recurse() \n",
    "#             except: # file has notes in a flat structure\n",
    "#                 notes_to_parse = midi.flat.notes\n",
    "\n",
    "#             for element in notes_to_parse:\n",
    "#                 if isinstance(element, note.Note):\n",
    "#                     song.append(str(element.pitch))\n",
    "#                 elif isinstance(element, chord.Chord):\n",
    "#                     song.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "#     return notes\n",
    "\n",
    "\"\"\" Train a Neural Network to generate music \"\"\"\n",
    "# Get notes from midi files\n",
    "input_dir_choice = 3\n",
    "input_dir_names = [\"test\", \"Pokemon\", \"LoZ OOT\", \"Pokemon GSC\", \"Pokemon Battle\", \"Undertale\", \"ABBA\"]\n",
    "\n",
    "input_path = \"../\" + input_dir_names[input_dir_choice] + \" MIDIs/\"\n",
    "# example of each mode: 0 - C, 1 - major, 2 - Cmajor\n",
    "# notes = get_notes_with_key(input_path, \"minor\", 1)\n",
    "notes = get_notes(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now use an algo to determine the key of each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ../Pokemon GSC MIDIs\\Pokemon Gold, Silver, Crystal - Cinnabar Island (HGSS Version).mid\n",
      "G major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon Gold, Silver, Crystal - S.S. Aqua .mid\n",
      "G major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Azalea TownBlackthorn City.mid\n",
      "C# major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Bicycle.mid\n",
      "E minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Bug Catching Contest.mid\n",
      "E minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Burned Tower.mid\n",
      "E minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Champion Battle.mid\n",
      "G# minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Cherrygrove CityMahogany Town.mid\n",
      "F major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Dance Theatre.mid\n",
      "A minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Dark Cave.mid\n",
      "A- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Dragons Den.mid\n",
      "C# minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Ecruteak CityCianwood City.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Girl Trainer Confrontation.mid\n",
      "E major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Goldenrod City.mid\n",
      "A- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Gym Leader Defeated.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Gym.mid\n",
      "G major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Indigo Plateau.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Johto Gym Leader Battle.mid\n",
      "A- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Johto Wild Pokemon Battle.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Kanto Gym Leader Battle.mid\n",
      "G# minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Lavender Town.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Menu.mid\n",
      "C# minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - National Park.mid\n",
      "B- minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - New Bark Town.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Olivine Lighthouse.mid\n",
      "C# minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Pokemon Lullaby.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Pokemon March.mid\n",
      "E- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Professor Elms Lab.mid\n",
      "F major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Professor Oaks Theme.mid\n",
      "E major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Rival Battle.mid\n",
      "G# minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 27.mid\n",
      "A minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 29.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 32.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 38.mid\n",
      "B major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Route 42.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Saffron City.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Show Me Around.mid\n",
      "A major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Sprout Tower.mid\n",
      "B- minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Staff Credits.mid\n",
      "G major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Surf.mid\n",
      "E- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Team RocketRadio Tower Takeover.mid\n",
      "A- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Tin Tower.mid\n",
      "F minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Title.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Union Cave.mid\n",
      "B- minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Victory Road.mid\n",
      "A minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon GoldSilverCrystal - Violet CityOlivine City.mid\n",
      "B major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Cerulean City.mid\n",
      "E major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Cinnabar Island.mid\n",
      "G major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Game Corner.mid\n",
      "C minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Indigo Plateau.mid\n",
      "D minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Instructions.mid\n",
      "F# major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Lyras Theme.mid\n",
      "E- major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - New Bark Town.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Pokemaniac Encounter.mid\n",
      "E- minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Pokemon Center.mid\n",
      "D major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - PokeWalker Synchronisation.mid\n",
      "E major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Route 4748.mid\n",
      "F major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Safari Zone Gate.mid\n",
      "A major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Team Rocket Hideout.mid\n",
      "B- minor\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Title.mid\n",
      "C major\n",
      "Parsing ../Pokemon GSC MIDIs\\Pokemon HeartGoldSoulSilver - Viridian Forest.mid\n",
      "C major\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Gmajor': 5,\n",
       " 'C#major': 1,\n",
       " 'Eminor': 3,\n",
       " 'G#minor': 3,\n",
       " 'Fmajor': 3,\n",
       " 'Aminor': 3,\n",
       " 'A-major': 4,\n",
       " 'C#minor': 3,\n",
       " 'Cmajor': 8,\n",
       " 'Emajor': 4,\n",
       " 'Dmajor': 8,\n",
       " 'B-minor': 4,\n",
       " 'E-major': 3,\n",
       " 'Bmajor': 2,\n",
       " 'Amajor': 2,\n",
       " 'Fminor': 1,\n",
       " 'Cminor': 1,\n",
       " 'Dminor': 1,\n",
       " 'F#major': 1,\n",
       " 'E-minor': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_key(path):\n",
    "    key_count = dict()\n",
    "    for file in glob.glob(path + \"*.mid\"):\n",
    "        print(\"Parsing %s\" % file)\n",
    "        \n",
    "        song = []\n",
    "        midi = converter.parse(file)\n",
    "        \n",
    "        key = midi.analyze('key')\n",
    "        key_string = key.tonic.name + key.mode\n",
    "        if (key_string in key_count): \n",
    "            key_count[key_string] += 1\n",
    "        else: \n",
    "            key_count[key_string] = 1\n",
    "        print(key.tonic.name, key.mode)\n",
    "    return key_count\n",
    "\n",
    "key_count = print_key(input_path)\n",
    "# key_count = print_key(\"../Undertale MIDIs/\")\n",
    "key_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will find all possible notes and use this to determine how to alter the data to a machine readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 25, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possibleNotes = set([item[0] for sublist in notes for item in sublist])\n",
    "\n",
    "# Processing for offsets\n",
    "possibleOffsets = []\n",
    "possibleDurations = []\n",
    "\n",
    "# For each song\n",
    "for index, song in enumerate(notes):\n",
    "    song_length = len(song)\n",
    "    \n",
    "    # For each note, calculate the difference in offset between this and the previous note\n",
    "    song_offsets = []\n",
    "    song_durations = []\n",
    "    for idx in range(song_length):\n",
    "        offset = offset = round(song[idx][1] - song[idx - 1][1], 3) if idx > 1 else 0.0\n",
    "        song_offsets.append(offset)\n",
    "        if offset not in possibleOffsets:\n",
    "            possibleOffsets.append(offset)\n",
    "        \n",
    "        duration = song[idx][2].quarterLength\n",
    "        song_durations.append(duration)\n",
    "        if duration not in possibleDurations:\n",
    "            possibleDurations.append(duration)\n",
    "            \n",
    "    # Update the notes to reflect this\n",
    "    for idx in range(song_length):\n",
    "        notes[index][idx][1] = song_offsets[idx]\n",
    "        notes[index][idx][2] = song_durations[idx]\n",
    "\n",
    "n_notes = len(possibleNotes)\n",
    "n_offset = len(possibleOffsets)\n",
    "n_duration = len(possibleDurations)\n",
    "\n",
    "\n",
    "possibleNotes = np.array(list(possibleNotes))\n",
    "possibleOffsets = np.array(list(possibleOffsets))\n",
    "possibleDurations = np.array(list(possibleDurations))\n",
    "notes = np.array([list([list(subsublist) for subsublist in sublist]) for sublist in notes])\n",
    "len(possibleNotes), len(possibleOffsets), len(possibleDurations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will prepare the sequences of notes by looking at each song individually. I will first grab an arrays of size **sequence_length** with a stride of **step_size** from each song. Then I will map the chords to integers so the model can learn from that and normalize the input between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19486, 100, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_sequences(notes, possibleNotes, possibleOffsets, possibleDurations):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    song_end_indices = []\n",
    "    sequence_length = 100\n",
    "    step_size = 1\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    pitchnames = sorted(possibleNotes)\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    # create a dictionary to map offset to integers\n",
    "    offsetnames = sorted(possibleOffsets)\n",
    "    offset_to_int = dict((offset, number) for number, offset in enumerate(offsetnames))\n",
    "    \n",
    "    # create a dictionary to map duration to integers\n",
    "    durationnames = sorted(possibleDurations)\n",
    "    duration_to_int = dict((duration, number) for number, duration in enumerate(durationnames))\n",
    "    \n",
    "    # find number of each possible choice for normalization\n",
    "    n_notes = len(possibleNotes)\n",
    "    n_offset = len(possibleOffsets)\n",
    "    n_duration = len(possibleDurations)\n",
    "\n",
    "    network_input = []\n",
    "    network_output_notes = []\n",
    "    network_output_offset = []\n",
    "    network_output_duration = []\n",
    "\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for song in notes:\n",
    "        for i in range(0, len(song) - sequence_length, step_size):\n",
    "            sequence_in = song[i:i + sequence_length]\n",
    "            sequence_out = song[i + sequence_length]\n",
    "            network_input.append([np.array([note_to_int[row[0]] / float(n_notes), offset_to_int[row[1]] / float(n_offset), duration_to_int[row[2]] / float(n_duration)]) for row in sequence_in])\n",
    "            network_output_notes.append(np.array([note_to_int[sequence_out[0]]]))\n",
    "            network_output_offset.append(np.array([offset_to_int[sequence_out[1]]]))\n",
    "            network_output_duration.append(np.array([duration_to_int[sequence_out[2]]]))\n",
    "        song_end_indices.append(len(network_input)-1)\n",
    "\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    n_patterns = len(network_input)\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 3))\n",
    "\n",
    "    # Make one-hot-encoding\n",
    "    network_output_notes = np_utils.to_categorical(network_output_notes, num_classes=n_notes)\n",
    "    network_output_offset = np_utils.to_categorical(network_output_offset, num_classes=n_offset)\n",
    "    network_output_duration = np_utils.to_categorical(network_output_duration, num_classes=n_duration)\n",
    "\n",
    "\n",
    "    return (network_input, network_output_notes, network_output_offset, network_output_duration, song_end_indices)\n",
    "\n",
    "network_input, network_output_notes, network_output_offset, network_output_duration, song_end_indices = prepare_sequences(notes, possibleNotes, possibleOffsets, possibleDurations)\n",
    "network_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, rows, network_input, n_notes, n_offset, n_duration):\n",
    "        self.seq_length = rows\n",
    "        self.seq_shape = (self.seq_length, 3)\n",
    "        self.latent_dim = 100\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss =[]\n",
    "        self.n_notes = n_notes\n",
    "        self.n_offset = n_offset\n",
    "        self.n_duration = n_duration\n",
    "        self.batch_size = 128\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator(network_input)\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates note sequences\n",
    "        z = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
    "        generated_seq = self.generator(z)\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated_seq)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        self.outputDest = '../output/GAN_' + str(int(time.time())) + '/'\n",
    "        if not os.path.exists(self.outputDest):\n",
    "            os.makedirs(self.outputDest)\n",
    "\n",
    "    def build_discriminator(self, network_input):\n",
    "        \n",
    "        input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
    "        lstm_1 = CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True)(input)\n",
    "        dropout_1 = Dropout(0.3)(lstm_1)\n",
    "        lstm_2 = Bidirectional(CuDNNLSTM(512, return_sequences=True))(dropout_1)\n",
    "        dropout_2 = Dropout(0.3)(lstm_2)\n",
    "        lstm_3 = Bidirectional(CuDNNLSTM(512))(dropout_2)\n",
    "        dense_1 = Dense(256)(lstm_3)\n",
    "        dropout_3 = Dropout(0.3)(dense_1)\n",
    "        output_d = Dense(1, activation='sigmoid')(dropout_3)\n",
    "        model = Model(inputs=input, outputs=output_d)\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "\n",
    "#         model = Sequential()\n",
    "#         model.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
    "#         model.add(Dropout(0.3))\n",
    "#         model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True)))\n",
    "#         model.add(Dropout(0.3))\n",
    "#         model.add(Bidirectional(CuDNNLSTM(512)))\n",
    "#         model.add(Dense(256))\n",
    "#         model.add(Dropout(0.3))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "#         model.summary()\n",
    "\n",
    "#         seq = Input(shape=self.seq_shape)\n",
    "#         validity = model(seq)\n",
    "\n",
    "#         return Model(seq, validity)\n",
    "      \n",
    "    def build_generator(self):\n",
    "\n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(128, input_dim=self.latent_dim))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Dense(256))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
    "#         model.add(Reshape(self.seq_shape))\n",
    "#         model.summary()\n",
    "        \n",
    "#         noise = Input(shape=(self.latent_dim,))\n",
    "#         seq = model(noise)\n",
    "\n",
    "#         return Model(noise, seq)\n",
    "    \n",
    "        input_g = Input(shape=(self.latent_dim, network_input.shape[2]))\n",
    "        dense_g_1 = Dense(128, input_dim=(self.latent_dim, network_input.shape[2]))(input_g)\n",
    "        lrelu_g_1 = LeakyReLU(alpha=0.2)(dense_g_1)\n",
    "        batch_norm_g_1 = BatchNormalization(momentum=0.8)(lrelu_g_1)\n",
    "        dense_g_2 = Dense(256)(batch_norm_g_1)\n",
    "        lrelu_g_2 = LeakyReLU(alpha=0.2)(dense_g_2)\n",
    "        batch_norm_g_2 = BatchNormalization(momentum=0.8)(lrelu_g_2)\n",
    "        output_notes = Dense(self.n_notes, activation='tanh')(batch_norm_g_2)\n",
    "        output_offset = Dense(self.n_offset, activation='tanh')(batch_norm_g_2)\n",
    "        output_duration = Dense(self.n_duration, activation='tanh')(batch_norm_g_2)\n",
    "        x = concatenate([output_notes, output_offset, output_duration])\n",
    "        dense_g_3 = Dense(3, activation='tanh')(x)\n",
    "        \n",
    "        model = Model(inputs=input_g, outputs=dense_g_3)\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs, batch_size=128, sample_interval=50):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Training the model\n",
    "        for epoch in range(epochs+1):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_seqs = X_train[idx]\n",
    "\n",
    "            # Add some random noise\n",
    "            noise1 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            noise2 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            noise3 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            noise = []\n",
    "            for idx in range(batch_size):\n",
    "                noise.append([noise1[idx], noise2[idx], noise3[idx]])\n",
    "            noise = np.asarray(noise)\n",
    "            noise = np.transpose(noise, (0, 2, 1))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  Training the Generator\n",
    "            noise1 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            noise2 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            noise3 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            noise = []\n",
    "            for idx in range(batch_size):\n",
    "                noise.append([noise1[idx], noise2[idx], noise3[idx]])\n",
    "            noise = np.asarray(noise)\n",
    "            noise = np.transpose(noise, (0, 2, 1))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, real)\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            self.disc_loss.append(d_loss[0])\n",
    "            self.gen_loss.append(g_loss)\n",
    "            \n",
    "              # Save model often\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.generator.save(self.outputDest + \"GANmodel_weights_\" + str(epoch) + \".hdf5\")\n",
    "                \n",
    "    def generate_notes(self, input_notes, possibleNotes, possibleOffsets, possibleDurations):\n",
    "        # Get pitch names and store in a dictionary\n",
    "        notes = input_notes\n",
    "        # create a dictionary to map pitches to integers\n",
    "        pitchnames = sorted(possibleNotes)\n",
    "        int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "        # create a dictionary to map offset to integers\n",
    "        offsetnames = sorted(possibleOffsets)\n",
    "        int_to_offset = dict((number, offset) for number, offset in enumerate(offsetnames))\n",
    "\n",
    "        # create a dictionary to map duration to integers\n",
    "        durationnames = sorted(possibleDurations)\n",
    "        int_to_duration = dict((number, duration) for number, duration in enumerate(durationnames))\n",
    "\n",
    "        # find number of each possible choice for normalization\n",
    "        n_notes = len(possibleNotes)\n",
    "        n_offset = len(possibleOffsets)\n",
    "        n_duration = len(possibleDurations)\n",
    "        \n",
    "        # Use random noise to generate sequences\n",
    "        noise1 = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        noise2 = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        noise3 = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        noise = [noise1, noise2, noise3]\n",
    "        noise = np.asarray(noise)\n",
    "        noise = np.transpose(noise, (1, 2, 0))\n",
    "        predictions = self.generator.predict(noise)\n",
    "        \n",
    "        pred_notes = [(x[0]+1)*n_notes/2 for x in predictions[0]]\n",
    "        pred_notes = [int_to_note[min(int(x), n_notes - 1)] for x in pred_notes]\n",
    "        pred_offset = [(x[1]+1)*n_offset/2 for x in predictions[0]]\n",
    "        pred_offset = [int_to_offset[min(int(x), n_offset - 1)] for x in pred_offset]\n",
    "        pred_duration = [(x[2]+1)*n_duration/2 for x in predictions[0]]\n",
    "        pred_duration = [int_to_duration[min(int(x), n_duration - 1)] for x in pred_duration]\n",
    "        pred_full = []\n",
    "        for (note, offset, duration) in zip(pred_notes, pred_offset, pred_duration): \n",
    "            pred_full.append([note, offset, duration])\n",
    "        print(pred_full)\n",
    "        \n",
    "        return pred_full\n",
    "        \n",
    "    def create_midi(self, prediction_output, filename):\n",
    "        \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "            from the notes \"\"\"\n",
    "        offset = 0\n",
    "        output_notes = []\n",
    "\n",
    "        # create note and chord objects based on the values generated by the model\n",
    "        count = 0\n",
    "        for pattern in prediction_output:\n",
    "            note_str = pattern[0]\n",
    "            offset_str = pattern[1]\n",
    "            duration_str = pattern[2]\n",
    "            if \"#-\" in note_str:# To fix a rare exception using 2 accidentals\n",
    "                continue\n",
    "            # pattern is a chord\n",
    "            if ('.' in note_str) or note_str.isdigit():\n",
    "                notes_in_chord = note_str.split('.')\n",
    "                notes = []\n",
    "                for current_note in notes_in_chord:\n",
    "                    new_note = note.Note(int(current_note))\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    notes.append(new_note)\n",
    "                new_chord = chord.Chord(notes)\n",
    "                new_chord.offset = offset\n",
    "                new_note.duration = D.Duration(float(duration_str))\n",
    "                output_notes.append(new_chord)\n",
    "            # pattern is a note\n",
    "            else:\n",
    "                new_note = note.Note(note_str)\n",
    "                new_note.offset = offset\n",
    "                new_note.duration = D.Duration(float(duration_str))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                output_notes.append(new_note)\n",
    "            # increase offset each iteration so that notes do not stack\n",
    "            offset += (float(prediction_output[count + 1][1])) if (count + 1 < len(prediction_output)) else 0\n",
    "            count += 1\n",
    "\n",
    "        midi_stream = stream.Stream(output_notes)\n",
    "        midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
    "        \n",
    "    def generate_midi_from_saves(self, input_notes):\n",
    "        # Have each model make a song\n",
    "        count = 0\n",
    "        for model_path in glob.glob(self.outputDest + \"*.hdf5\"):\n",
    "            print(\"Composing from %s\" % model_path)\n",
    "            self.generator.load_weights(model_path)\n",
    "            prediction_notes = self.generate_notes(input_notes)\n",
    "            self.create_midi(prediction_notes, self.outputDest + 'GAN_output_' + str(count))\n",
    "            print(self.outputDest + 'GAN_output_' + str(count))\n",
    "            count += 1\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig(self.outputDest + 'GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_92 (InputLayer)        (None, 100, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_94 (CuDNNLSTM)    (None, 100, 512)          1058816   \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_63 (Bidirectio (None, 100, 1024)         4202496   \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_64 (Bidirectio (None, 1024)              6299648   \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 11,823,617\n",
      "Trainable params: 11,823,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_91\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_93 (InputLayer)           (None, 100, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 100, 128)     512         input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 100, 128)     0           dense_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 100, 128)     512         leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 100, 256)     33024       batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 100, 256)     0           dense_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 100, 256)     1024        leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 100, 306)     78642       batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 100, 25)      6425        batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 100, 29)      7453        batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 100, 360)     0           dense_255[0][0]                  \n",
      "                                                                 dense_256[0][0]                  \n",
      "                                                                 dense_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 100, 3)       1083        concatenate_32[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 128,675\n",
      "Trainable params: 127,907\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.702384, acc.: 17.50%] [G loss: 0.671679]\n",
      "1 [D loss: 0.650390, acc.: 50.00%] [G loss: 0.577322]\n",
      "2 [D loss: 0.921970, acc.: 50.00%] [G loss: 0.479861]\n",
      "3 [D loss: 0.832946, acc.: 50.00%] [G loss: 0.445945]\n",
      "4 [D loss: 0.912641, acc.: 50.00%] [G loss: 0.424157]\n",
      "5 [D loss: 0.950384, acc.: 50.00%] [G loss: 0.409101]\n",
      "6 [D loss: 1.037161, acc.: 50.00%] [G loss: 0.393490]\n",
      "7 [D loss: 1.030513, acc.: 50.00%] [G loss: 0.392890]\n",
      "8 [D loss: 1.106550, acc.: 50.00%] [G loss: 0.369813]\n",
      "9 [D loss: 1.071762, acc.: 50.00%] [G loss: 0.349249]\n",
      "10 [D loss: 1.160797, acc.: 50.00%] [G loss: 0.348649]\n",
      "11 [D loss: 1.188092, acc.: 50.00%] [G loss: 0.344551]\n",
      "12 [D loss: 1.168838, acc.: 50.00%] [G loss: 0.338398]\n",
      "13 [D loss: 1.156837, acc.: 50.00%] [G loss: 0.322532]\n",
      "14 [D loss: 1.272917, acc.: 50.00%] [G loss: 0.324470]\n",
      "15 [D loss: 1.208158, acc.: 50.00%] [G loss: 0.311696]\n",
      "16 [D loss: 1.231135, acc.: 50.00%] [G loss: 0.314314]\n",
      "17 [D loss: 1.239968, acc.: 50.00%] [G loss: 0.304606]\n",
      "18 [D loss: 1.287970, acc.: 50.00%] [G loss: 0.304700]\n",
      "19 [D loss: 1.251522, acc.: 50.00%] [G loss: 0.303140]\n",
      "20 [D loss: 1.300026, acc.: 50.00%] [G loss: 0.296675]\n",
      "21 [D loss: 1.345861, acc.: 50.00%] [G loss: 0.294989]\n",
      "22 [D loss: 1.250389, acc.: 50.00%] [G loss: 0.292362]\n",
      "23 [D loss: 1.327242, acc.: 50.00%] [G loss: 0.306897]\n",
      "24 [D loss: 1.322234, acc.: 50.00%] [G loss: 0.308000]\n",
      "25 [D loss: 1.275343, acc.: 50.00%] [G loss: 0.298285]\n",
      "26 [D loss: 1.313244, acc.: 50.00%] [G loss: 0.291756]\n",
      "27 [D loss: 1.350575, acc.: 50.00%] [G loss: 0.289664]\n",
      "28 [D loss: 1.264258, acc.: 50.00%] [G loss: 0.290985]\n",
      "29 [D loss: 1.322663, acc.: 50.00%] [G loss: 0.282011]\n",
      "30 [D loss: 1.371298, acc.: 50.00%] [G loss: 0.278963]\n",
      "31 [D loss: 1.333862, acc.: 50.00%] [G loss: 0.292034]\n",
      "32 [D loss: 1.334639, acc.: 50.00%] [G loss: 0.285600]\n",
      "33 [D loss: 1.340275, acc.: 50.00%] [G loss: 0.279343]\n",
      "34 [D loss: 1.353757, acc.: 50.00%] [G loss: 0.276708]\n",
      "35 [D loss: 1.320142, acc.: 50.00%] [G loss: 0.274639]\n",
      "36 [D loss: 1.349748, acc.: 50.00%] [G loss: 0.273602]\n",
      "37 [D loss: 1.378125, acc.: 50.00%] [G loss: 0.276738]\n",
      "38 [D loss: 1.358487, acc.: 50.00%] [G loss: 0.278871]\n",
      "39 [D loss: 1.331414, acc.: 50.00%] [G loss: 0.281057]\n",
      "40 [D loss: 1.367560, acc.: 50.00%] [G loss: 0.271222]\n",
      "41 [D loss: 1.363890, acc.: 50.00%] [G loss: 0.264387]\n",
      "42 [D loss: 1.411705, acc.: 50.00%] [G loss: 0.273895]\n",
      "43 [D loss: 1.341221, acc.: 50.00%] [G loss: 0.271581]\n",
      "44 [D loss: 1.351325, acc.: 50.00%] [G loss: 0.284010]\n",
      "45 [D loss: 1.371962, acc.: 50.00%] [G loss: 0.261720]\n",
      "46 [D loss: 1.354095, acc.: 50.00%] [G loss: 0.265382]\n",
      "47 [D loss: 1.425065, acc.: 50.00%] [G loss: 0.271457]\n",
      "48 [D loss: 1.323591, acc.: 50.00%] [G loss: 0.272502]\n",
      "49 [D loss: 1.400912, acc.: 50.00%] [G loss: 0.262999]\n",
      "50 [D loss: 1.344282, acc.: 50.00%] [G loss: 0.269401]\n",
      "51 [D loss: 1.373487, acc.: 50.00%] [G loss: 0.256604]\n",
      "52 [D loss: 1.383555, acc.: 50.00%] [G loss: 0.261038]\n",
      "53 [D loss: 1.382881, acc.: 50.00%] [G loss: 0.258688]\n",
      "54 [D loss: 1.368257, acc.: 50.00%] [G loss: 0.254475]\n",
      "55 [D loss: 1.407483, acc.: 50.00%] [G loss: 0.262199]\n",
      "56 [D loss: 1.382888, acc.: 50.00%] [G loss: 0.268424]\n",
      "57 [D loss: 1.358864, acc.: 50.00%] [G loss: 0.257432]\n",
      "58 [D loss: 1.335421, acc.: 50.00%] [G loss: 0.256861]\n",
      "59 [D loss: 1.375138, acc.: 50.00%] [G loss: 0.259238]\n",
      "60 [D loss: 1.397018, acc.: 50.00%] [G loss: 0.257255]\n",
      "61 [D loss: 1.369659, acc.: 50.00%] [G loss: 0.253299]\n",
      "62 [D loss: 1.365936, acc.: 50.00%] [G loss: 0.245992]\n",
      "63 [D loss: 1.391533, acc.: 50.00%] [G loss: 0.258393]\n",
      "64 [D loss: 1.395167, acc.: 50.00%] [G loss: 0.264903]\n",
      "65 [D loss: 1.359178, acc.: 50.00%] [G loss: 0.256247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 [D loss: 1.430605, acc.: 50.00%] [G loss: 0.249788]\n",
      "67 [D loss: 1.344798, acc.: 50.00%] [G loss: 0.261683]\n",
      "68 [D loss: 1.396559, acc.: 50.00%] [G loss: 0.253813]\n",
      "69 [D loss: 1.405634, acc.: 50.00%] [G loss: 0.254909]\n",
      "70 [D loss: 1.388078, acc.: 50.00%] [G loss: 0.253174]\n",
      "71 [D loss: 1.400743, acc.: 50.00%] [G loss: 0.251117]\n",
      "72 [D loss: 1.362457, acc.: 50.00%] [G loss: 0.246912]\n",
      "73 [D loss: 1.362908, acc.: 50.00%] [G loss: 0.245994]\n",
      "74 [D loss: 1.368716, acc.: 50.00%] [G loss: 0.239294]\n",
      "75 [D loss: 1.388490, acc.: 50.00%] [G loss: 0.237657]\n",
      "76 [D loss: 1.400863, acc.: 50.00%] [G loss: 0.246789]\n",
      "77 [D loss: 1.423239, acc.: 50.00%] [G loss: 0.239175]\n",
      "78 [D loss: 1.368089, acc.: 50.00%] [G loss: 0.240368]\n",
      "79 [D loss: 1.360234, acc.: 50.00%] [G loss: 0.238058]\n",
      "80 [D loss: 1.367920, acc.: 50.00%] [G loss: 0.204282]\n",
      "81 [D loss: 1.409402, acc.: 50.00%] [G loss: 0.248091]\n",
      "82 [D loss: 1.377644, acc.: 50.00%] [G loss: 0.221387]\n",
      "83 [D loss: 1.400956, acc.: 50.00%] [G loss: 0.206578]\n",
      "84 [D loss: 1.366601, acc.: 50.00%] [G loss: 0.223600]\n",
      "85 [D loss: 1.369169, acc.: 50.00%] [G loss: 0.215419]\n",
      "86 [D loss: 1.393167, acc.: 50.00%] [G loss: 0.210389]\n",
      "87 [D loss: 1.366348, acc.: 50.00%] [G loss: 0.230694]\n",
      "88 [D loss: 1.339911, acc.: 50.00%] [G loss: 0.212412]\n",
      "89 [D loss: 1.367081, acc.: 50.00%] [G loss: 0.217036]\n",
      "90 [D loss: 1.317691, acc.: 50.00%] [G loss: 0.215614]\n",
      "91 [D loss: 1.345887, acc.: 50.00%] [G loss: 0.210001]\n",
      "92 [D loss: 1.390921, acc.: 50.00%] [G loss: 0.205721]\n",
      "93 [D loss: 1.365258, acc.: 50.00%] [G loss: 0.204881]\n",
      "94 [D loss: 1.317989, acc.: 50.00%] [G loss: 0.215521]\n",
      "95 [D loss: 1.324765, acc.: 50.00%] [G loss: 0.208966]\n",
      "96 [D loss: 1.296282, acc.: 50.00%] [G loss: 0.193842]\n",
      "97 [D loss: 1.348526, acc.: 50.00%] [G loss: 0.203713]\n",
      "98 [D loss: 1.343008, acc.: 50.00%] [G loss: 0.198260]\n",
      "99 [D loss: 1.325127, acc.: 50.00%] [G loss: 0.211898]\n",
      "100 [D loss: 1.295083, acc.: 50.00%] [G loss: 0.206421]\n",
      "101 [D loss: 1.318867, acc.: 50.00%] [G loss: 0.186049]\n",
      "102 [D loss: 1.295403, acc.: 50.00%] [G loss: 0.207410]\n",
      "103 [D loss: 1.315864, acc.: 50.00%] [G loss: 0.203349]\n",
      "104 [D loss: 1.320254, acc.: 50.00%] [G loss: 0.183027]\n",
      "105 [D loss: 1.313029, acc.: 50.00%] [G loss: 0.209180]\n",
      "106 [D loss: 1.291570, acc.: 50.00%] [G loss: 0.204005]\n",
      "107 [D loss: 1.352280, acc.: 50.00%] [G loss: 0.195143]\n",
      "108 [D loss: 1.283463, acc.: 50.00%] [G loss: 0.184642]\n",
      "109 [D loss: 1.242017, acc.: 50.00%] [G loss: 0.188605]\n",
      "110 [D loss: 1.314017, acc.: 50.00%] [G loss: 0.200404]\n",
      "111 [D loss: 1.308948, acc.: 50.00%] [G loss: 0.191324]\n",
      "112 [D loss: 1.282184, acc.: 50.00%] [G loss: 0.190018]\n",
      "113 [D loss: 1.289940, acc.: 50.00%] [G loss: 0.187860]\n",
      "114 [D loss: 1.286744, acc.: 50.00%] [G loss: 0.193916]\n",
      "115 [D loss: 1.266282, acc.: 50.00%] [G loss: 0.190042]\n",
      "116 [D loss: 1.271719, acc.: 50.00%] [G loss: 0.168866]\n",
      "117 [D loss: 1.276491, acc.: 50.00%] [G loss: 0.186912]\n",
      "118 [D loss: 1.277806, acc.: 50.00%] [G loss: 0.172049]\n",
      "119 [D loss: 1.255206, acc.: 50.00%] [G loss: 0.187781]\n",
      "120 [D loss: 1.227791, acc.: 50.00%] [G loss: 0.177460]\n",
      "121 [D loss: 1.255653, acc.: 50.00%] [G loss: 0.193648]\n",
      "122 [D loss: 1.273051, acc.: 50.00%] [G loss: 0.189129]\n",
      "123 [D loss: 1.278789, acc.: 50.00%] [G loss: 0.185550]\n",
      "124 [D loss: 1.272861, acc.: 50.00%] [G loss: 0.174807]\n",
      "125 [D loss: 1.267261, acc.: 50.00%] [G loss: 0.180741]\n",
      "126 [D loss: 1.238070, acc.: 50.00%] [G loss: 0.185570]\n",
      "127 [D loss: 1.259087, acc.: 50.00%] [G loss: 0.182843]\n",
      "128 [D loss: 1.247791, acc.: 50.00%] [G loss: 0.172874]\n",
      "129 [D loss: 1.240818, acc.: 50.00%] [G loss: 0.171871]\n",
      "130 [D loss: 1.240776, acc.: 50.00%] [G loss: 0.172990]\n",
      "131 [D loss: 1.235857, acc.: 50.00%] [G loss: 0.185706]\n",
      "132 [D loss: 1.277367, acc.: 50.00%] [G loss: 0.178686]\n",
      "133 [D loss: 1.242315, acc.: 50.00%] [G loss: 0.179631]\n",
      "134 [D loss: 1.292978, acc.: 50.00%] [G loss: 0.166584]\n",
      "135 [D loss: 1.264419, acc.: 50.00%] [G loss: 0.176299]\n",
      "136 [D loss: 1.243952, acc.: 50.00%] [G loss: 0.189464]\n",
      "137 [D loss: 1.241916, acc.: 50.00%] [G loss: 0.175847]\n",
      "138 [D loss: 1.250630, acc.: 50.00%] [G loss: 0.175305]\n",
      "139 [D loss: 1.257001, acc.: 50.00%] [G loss: 0.173024]\n",
      "140 [D loss: 1.247442, acc.: 50.00%] [G loss: 0.165300]\n",
      "141 [D loss: 1.229533, acc.: 50.00%] [G loss: 0.161069]\n",
      "142 [D loss: 1.281575, acc.: 50.00%] [G loss: 0.164567]\n",
      "143 [D loss: 1.234470, acc.: 50.00%] [G loss: 0.179972]\n",
      "144 [D loss: 1.230170, acc.: 50.00%] [G loss: 0.186615]\n",
      "145 [D loss: 1.250006, acc.: 50.00%] [G loss: 0.172563]\n",
      "146 [D loss: 1.236597, acc.: 50.00%] [G loss: 0.175491]\n",
      "147 [D loss: 1.210439, acc.: 50.00%] [G loss: 0.168654]\n",
      "148 [D loss: 1.217912, acc.: 50.00%] [G loss: 0.164433]\n",
      "149 [D loss: 1.223985, acc.: 50.00%] [G loss: 0.173485]\n",
      "150 [D loss: 1.227901, acc.: 50.00%] [G loss: 0.158705]\n",
      "151 [D loss: 1.240522, acc.: 50.00%] [G loss: 0.160458]\n",
      "152 [D loss: 1.214125, acc.: 50.00%] [G loss: 0.162817]\n",
      "153 [D loss: 1.241290, acc.: 50.00%] [G loss: 0.163248]\n",
      "154 [D loss: 1.254555, acc.: 50.00%] [G loss: 0.153295]\n",
      "155 [D loss: 1.194900, acc.: 50.00%] [G loss: 0.153255]\n",
      "156 [D loss: 1.248904, acc.: 50.00%] [G loss: 0.162673]\n",
      "157 [D loss: 1.215065, acc.: 50.00%] [G loss: 0.166598]\n",
      "158 [D loss: 1.225623, acc.: 50.00%] [G loss: 0.153678]\n",
      "159 [D loss: 1.223300, acc.: 50.00%] [G loss: 0.176250]\n",
      "160 [D loss: 1.229287, acc.: 50.00%] [G loss: 0.167760]\n",
      "161 [D loss: 1.238476, acc.: 50.00%] [G loss: 0.179066]\n",
      "162 [D loss: 1.234930, acc.: 50.00%] [G loss: 0.160967]\n",
      "163 [D loss: 1.247975, acc.: 50.00%] [G loss: 0.148289]\n",
      "164 [D loss: 1.231599, acc.: 50.00%] [G loss: 0.155578]\n",
      "165 [D loss: 1.248214, acc.: 50.00%] [G loss: 0.168163]\n",
      "166 [D loss: 1.286418, acc.: 50.00%] [G loss: 0.156604]\n",
      "167 [D loss: 1.215580, acc.: 50.00%] [G loss: 0.152902]\n",
      "168 [D loss: 1.250183, acc.: 50.00%] [G loss: 0.174605]\n",
      "169 [D loss: 1.251448, acc.: 50.00%] [G loss: 0.162148]\n",
      "170 [D loss: 1.209298, acc.: 50.00%] [G loss: 0.176104]\n",
      "171 [D loss: 1.250304, acc.: 50.00%] [G loss: 0.158272]\n",
      "172 [D loss: 1.214920, acc.: 50.00%] [G loss: 0.172912]\n",
      "173 [D loss: 1.228915, acc.: 50.00%] [G loss: 0.166047]\n",
      "174 [D loss: 1.255580, acc.: 50.00%] [G loss: 0.159770]\n",
      "175 [D loss: 1.249767, acc.: 50.00%] [G loss: 0.152613]\n",
      "176 [D loss: 1.291377, acc.: 50.00%] [G loss: 0.148026]\n",
      "177 [D loss: 1.272315, acc.: 50.00%] [G loss: 0.157289]\n",
      "178 [D loss: 1.216347, acc.: 50.00%] [G loss: 0.151083]\n",
      "179 [D loss: 1.248921, acc.: 50.00%] [G loss: 0.150830]\n",
      "180 [D loss: 1.242611, acc.: 50.00%] [G loss: 0.160877]\n",
      "181 [D loss: 1.209994, acc.: 50.00%] [G loss: 0.163109]\n",
      "182 [D loss: 1.237083, acc.: 50.00%] [G loss: 0.153698]\n",
      "183 [D loss: 1.213978, acc.: 50.00%] [G loss: 0.154140]\n",
      "184 [D loss: 1.240629, acc.: 50.00%] [G loss: 0.164595]\n",
      "185 [D loss: 1.208943, acc.: 50.00%] [G loss: 0.156907]\n",
      "186 [D loss: 1.254581, acc.: 50.00%] [G loss: 0.163526]\n",
      "187 [D loss: 1.222764, acc.: 50.00%] [G loss: 0.162766]\n",
      "188 [D loss: 1.246634, acc.: 50.00%] [G loss: 0.158214]\n",
      "189 [D loss: 1.257532, acc.: 50.00%] [G loss: 0.164334]\n",
      "190 [D loss: 1.215034, acc.: 50.00%] [G loss: 0.163115]\n",
      "191 [D loss: 1.230099, acc.: 50.00%] [G loss: 0.155657]\n",
      "192 [D loss: 1.232863, acc.: 50.00%] [G loss: 0.151791]\n",
      "193 [D loss: 1.261004, acc.: 50.00%] [G loss: 0.145586]\n",
      "194 [D loss: 1.215664, acc.: 50.00%] [G loss: 0.148659]\n",
      "195 [D loss: 1.230868, acc.: 50.00%] [G loss: 0.161083]\n",
      "196 [D loss: 1.219360, acc.: 50.00%] [G loss: 0.147635]\n",
      "197 [D loss: 1.231414, acc.: 50.00%] [G loss: 0.156989]\n",
      "198 [D loss: 1.210749, acc.: 50.00%] [G loss: 0.149474]\n",
      "199 [D loss: 1.251082, acc.: 50.00%] [G loss: 0.148183]\n",
      "200 [D loss: 1.222331, acc.: 50.00%] [G loss: 0.156274]\n",
      "201 [D loss: 1.232314, acc.: 50.00%] [G loss: 0.158594]\n",
      "202 [D loss: 1.227469, acc.: 50.00%] [G loss: 0.158757]\n",
      "203 [D loss: 1.221788, acc.: 50.00%] [G loss: 0.161966]\n",
      "204 [D loss: 1.289986, acc.: 50.00%] [G loss: 0.143818]\n",
      "205 [D loss: 1.282258, acc.: 50.00%] [G loss: 0.144116]\n",
      "206 [D loss: 1.358362, acc.: 50.00%] [G loss: 0.168641]\n",
      "207 [D loss: 1.258854, acc.: 50.00%] [G loss: 0.170660]\n",
      "208 [D loss: 1.325452, acc.: 50.00%] [G loss: 0.147132]\n",
      "209 [D loss: 1.309522, acc.: 50.00%] [G loss: 0.136307]\n",
      "210 [D loss: 1.260449, acc.: 50.00%] [G loss: 0.147115]\n",
      "211 [D loss: 1.323547, acc.: 50.00%] [G loss: 0.134353]\n",
      "212 [D loss: 1.269302, acc.: 50.00%] [G loss: 0.133940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 [D loss: 1.279308, acc.: 50.00%] [G loss: 0.126625]\n",
      "214 [D loss: 1.233721, acc.: 50.00%] [G loss: 0.156105]\n",
      "215 [D loss: 1.263687, acc.: 50.00%] [G loss: 0.152446]\n",
      "216 [D loss: 1.215186, acc.: 50.00%] [G loss: 0.156286]\n",
      "217 [D loss: 1.223152, acc.: 50.00%] [G loss: 0.151936]\n",
      "218 [D loss: 1.227067, acc.: 50.00%] [G loss: 0.148874]\n",
      "219 [D loss: 1.266294, acc.: 50.00%] [G loss: 0.155171]\n",
      "220 [D loss: 1.232980, acc.: 50.00%] [G loss: 0.148394]\n",
      "221 [D loss: 1.240356, acc.: 50.00%] [G loss: 0.154852]\n",
      "222 [D loss: 1.239254, acc.: 50.00%] [G loss: 0.146287]\n",
      "223 [D loss: 1.242967, acc.: 50.00%] [G loss: 0.162219]\n",
      "224 [D loss: 1.240829, acc.: 50.00%] [G loss: 0.151360]\n",
      "225 [D loss: 1.236548, acc.: 50.00%] [G loss: 0.148991]\n",
      "226 [D loss: 1.226550, acc.: 50.00%] [G loss: 0.157267]\n",
      "227 [D loss: 1.237800, acc.: 50.00%] [G loss: 0.153954]\n",
      "228 [D loss: 1.265351, acc.: 50.00%] [G loss: 0.153623]\n",
      "229 [D loss: 1.249692, acc.: 50.00%] [G loss: 0.143111]\n",
      "230 [D loss: 1.223758, acc.: 50.00%] [G loss: 0.153133]\n",
      "231 [D loss: 1.228554, acc.: 50.00%] [G loss: 0.148547]\n",
      "232 [D loss: 1.242532, acc.: 50.00%] [G loss: 0.157593]\n",
      "233 [D loss: 1.256838, acc.: 50.00%] [G loss: 0.161367]\n",
      "234 [D loss: 1.190596, acc.: 50.00%] [G loss: 0.166426]\n",
      "235 [D loss: 1.249246, acc.: 50.00%] [G loss: 0.147781]\n",
      "236 [D loss: 1.255704, acc.: 50.00%] [G loss: 0.143227]\n",
      "237 [D loss: 1.238817, acc.: 50.00%] [G loss: 0.142181]\n",
      "238 [D loss: 1.232425, acc.: 50.00%] [G loss: 0.150409]\n",
      "239 [D loss: 1.217793, acc.: 50.00%] [G loss: 0.164190]\n",
      "240 [D loss: 1.247367, acc.: 50.00%] [G loss: 0.150201]\n",
      "241 [D loss: 1.250071, acc.: 50.00%] [G loss: 0.147633]\n",
      "242 [D loss: 1.231962, acc.: 50.00%] [G loss: 0.154254]\n",
      "243 [D loss: 1.263785, acc.: 50.00%] [G loss: 0.147857]\n",
      "244 [D loss: 1.229022, acc.: 50.00%] [G loss: 0.152986]\n",
      "245 [D loss: 1.245207, acc.: 50.00%] [G loss: 0.160540]\n",
      "246 [D loss: 1.242420, acc.: 50.00%] [G loss: 0.145988]\n",
      "247 [D loss: 1.256948, acc.: 50.00%] [G loss: 0.144883]\n",
      "248 [D loss: 1.230081, acc.: 50.00%] [G loss: 0.149436]\n",
      "249 [D loss: 1.232305, acc.: 50.00%] [G loss: 0.156148]\n",
      "250 [D loss: 1.232774, acc.: 50.00%] [G loss: 0.152988]\n",
      "251 [D loss: 1.244386, acc.: 50.00%] [G loss: 0.156583]\n",
      "252 [D loss: 1.248595, acc.: 50.00%] [G loss: 0.160636]\n",
      "253 [D loss: 1.207403, acc.: 50.00%] [G loss: 0.158843]\n",
      "254 [D loss: 1.253488, acc.: 50.00%] [G loss: 0.145540]\n",
      "255 [D loss: 1.239478, acc.: 50.00%] [G loss: 0.150582]\n",
      "256 [D loss: 1.242520, acc.: 50.00%] [G loss: 0.144668]\n",
      "257 [D loss: 1.240000, acc.: 50.00%] [G loss: 0.144230]\n",
      "258 [D loss: 1.230883, acc.: 50.00%] [G loss: 0.150641]\n",
      "259 [D loss: 1.248758, acc.: 50.00%] [G loss: 0.147352]\n",
      "260 [D loss: 1.241602, acc.: 50.00%] [G loss: 0.156638]\n",
      "261 [D loss: 1.233250, acc.: 50.00%] [G loss: 0.155389]\n",
      "262 [D loss: 1.233575, acc.: 50.00%] [G loss: 0.144673]\n",
      "263 [D loss: 1.240453, acc.: 50.00%] [G loss: 0.148624]\n",
      "264 [D loss: 1.230596, acc.: 50.00%] [G loss: 0.149128]\n",
      "265 [D loss: 1.251746, acc.: 50.00%] [G loss: 0.158259]\n",
      "266 [D loss: 1.228472, acc.: 50.00%] [G loss: 0.157772]\n",
      "267 [D loss: 1.247399, acc.: 50.00%] [G loss: 0.149490]\n",
      "268 [D loss: 1.213164, acc.: 50.00%] [G loss: 0.149770]\n",
      "269 [D loss: 1.273443, acc.: 50.00%] [G loss: 0.151764]\n",
      "270 [D loss: 1.237428, acc.: 50.00%] [G loss: 0.138587]\n",
      "271 [D loss: 1.265705, acc.: 50.00%] [G loss: 0.146132]\n",
      "272 [D loss: 1.221101, acc.: 50.00%] [G loss: 0.150353]\n",
      "273 [D loss: 1.241598, acc.: 50.00%] [G loss: 0.160387]\n",
      "274 [D loss: 1.215692, acc.: 50.00%] [G loss: 0.151129]\n",
      "275 [D loss: 1.248649, acc.: 50.00%] [G loss: 0.156314]\n",
      "276 [D loss: 1.253534, acc.: 50.00%] [G loss: 0.154522]\n",
      "277 [D loss: 1.241874, acc.: 50.00%] [G loss: 0.142413]\n",
      "278 [D loss: 1.248341, acc.: 50.00%] [G loss: 0.158073]\n",
      "279 [D loss: 1.240726, acc.: 50.00%] [G loss: 0.150027]\n",
      "280 [D loss: 1.242790, acc.: 50.00%] [G loss: 0.150139]\n",
      "281 [D loss: 1.218951, acc.: 50.00%] [G loss: 0.145323]\n",
      "282 [D loss: 1.240082, acc.: 50.00%] [G loss: 0.154427]\n",
      "283 [D loss: 1.278275, acc.: 50.00%] [G loss: 0.154560]\n",
      "284 [D loss: 1.227545, acc.: 50.00%] [G loss: 0.132666]\n",
      "285 [D loss: 1.232802, acc.: 50.00%] [G loss: 0.147372]\n",
      "286 [D loss: 1.211952, acc.: 50.00%] [G loss: 0.140970]\n",
      "287 [D loss: 1.225661, acc.: 50.00%] [G loss: 0.156923]\n",
      "288 [D loss: 1.243093, acc.: 50.00%] [G loss: 0.148990]\n",
      "289 [D loss: 1.243156, acc.: 50.00%] [G loss: 0.146483]\n",
      "290 [D loss: 1.244824, acc.: 50.00%] [G loss: 0.155331]\n",
      "291 [D loss: 1.248354, acc.: 50.00%] [G loss: 0.154765]\n",
      "292 [D loss: 1.259487, acc.: 50.00%] [G loss: 0.141082]\n",
      "293 [D loss: 1.247159, acc.: 50.00%] [G loss: 0.145810]\n",
      "294 [D loss: 1.205044, acc.: 50.00%] [G loss: 0.153215]\n",
      "295 [D loss: 1.227878, acc.: 50.00%] [G loss: 0.145874]\n",
      "296 [D loss: 1.232700, acc.: 50.00%] [G loss: 0.146102]\n",
      "297 [D loss: 1.268574, acc.: 50.00%] [G loss: 0.146979]\n",
      "298 [D loss: 1.260250, acc.: 50.00%] [G loss: 0.160593]\n",
      "299 [D loss: 1.241801, acc.: 50.00%] [G loss: 0.148910]\n",
      "300 [D loss: 1.276997, acc.: 50.00%] [G loss: 0.146076]\n",
      "301 [D loss: 1.244535, acc.: 50.00%] [G loss: 0.151353]\n",
      "302 [D loss: 1.255540, acc.: 50.00%] [G loss: 0.143952]\n",
      "303 [D loss: 1.246189, acc.: 50.00%] [G loss: 0.161136]\n",
      "304 [D loss: 1.254543, acc.: 50.00%] [G loss: 0.162697]\n",
      "305 [D loss: 1.281452, acc.: 50.00%] [G loss: 0.152738]\n",
      "306 [D loss: 1.303893, acc.: 50.00%] [G loss: 0.132776]\n",
      "307 [D loss: 1.312935, acc.: 50.00%] [G loss: 0.129407]\n",
      "308 [D loss: 1.281402, acc.: 50.00%] [G loss: 0.144191]\n",
      "309 [D loss: 1.280234, acc.: 50.00%] [G loss: 0.139421]\n",
      "310 [D loss: 1.258736, acc.: 50.00%] [G loss: 0.151762]\n",
      "311 [D loss: 1.257105, acc.: 50.00%] [G loss: 0.161853]\n",
      "312 [D loss: 1.248030, acc.: 50.00%] [G loss: 0.158652]\n",
      "313 [D loss: 1.264515, acc.: 50.00%] [G loss: 0.141939]\n",
      "314 [D loss: 1.248158, acc.: 50.00%] [G loss: 0.141449]\n",
      "315 [D loss: 1.243227, acc.: 50.00%] [G loss: 0.159715]\n",
      "316 [D loss: 1.226484, acc.: 50.00%] [G loss: 0.156650]\n",
      "317 [D loss: 1.290867, acc.: 50.00%] [G loss: 0.146396]\n",
      "318 [D loss: 1.262960, acc.: 50.00%] [G loss: 0.145208]\n",
      "319 [D loss: 1.281964, acc.: 50.00%] [G loss: 0.151497]\n",
      "320 [D loss: 1.258753, acc.: 50.00%] [G loss: 0.143165]\n",
      "321 [D loss: 1.232782, acc.: 50.00%] [G loss: 0.150987]\n",
      "322 [D loss: 1.205433, acc.: 50.00%] [G loss: 0.147957]\n",
      "323 [D loss: 1.254804, acc.: 50.00%] [G loss: 0.149387]\n",
      "324 [D loss: 1.285041, acc.: 50.00%] [G loss: 0.152981]\n",
      "325 [D loss: 1.210649, acc.: 50.00%] [G loss: 0.152482]\n",
      "326 [D loss: 1.240737, acc.: 50.00%] [G loss: 0.150976]\n",
      "327 [D loss: 1.248191, acc.: 50.00%] [G loss: 0.143548]\n",
      "328 [D loss: 1.240127, acc.: 50.00%] [G loss: 0.141192]\n",
      "329 [D loss: 1.295853, acc.: 50.00%] [G loss: 0.153953]\n",
      "330 [D loss: 1.262168, acc.: 50.00%] [G loss: 0.137096]\n",
      "331 [D loss: 1.244285, acc.: 50.00%] [G loss: 0.148692]\n",
      "332 [D loss: 1.265067, acc.: 50.00%] [G loss: 0.150727]\n",
      "333 [D loss: 1.268217, acc.: 50.00%] [G loss: 0.145860]\n",
      "334 [D loss: 1.275408, acc.: 50.00%] [G loss: 0.150634]\n",
      "335 [D loss: 1.249331, acc.: 50.00%] [G loss: 0.148693]\n",
      "336 [D loss: 1.268480, acc.: 50.00%] [G loss: 0.154255]\n",
      "337 [D loss: 1.290312, acc.: 50.00%] [G loss: 0.152158]\n",
      "338 [D loss: 1.272898, acc.: 50.00%] [G loss: 0.157932]\n",
      "339 [D loss: 1.243443, acc.: 50.00%] [G loss: 0.141188]\n",
      "340 [D loss: 1.268012, acc.: 50.00%] [G loss: 0.152440]\n",
      "341 [D loss: 1.268050, acc.: 50.00%] [G loss: 0.153553]\n",
      "342 [D loss: 1.290910, acc.: 50.00%] [G loss: 0.147025]\n",
      "343 [D loss: 1.274307, acc.: 50.00%] [G loss: 0.147588]\n",
      "344 [D loss: 1.291591, acc.: 50.00%] [G loss: 0.143866]\n",
      "345 [D loss: 1.265177, acc.: 50.00%] [G loss: 0.143950]\n",
      "346 [D loss: 1.246705, acc.: 50.00%] [G loss: 0.146880]\n",
      "347 [D loss: 1.271703, acc.: 50.00%] [G loss: 0.150580]\n",
      "348 [D loss: 1.247516, acc.: 50.00%] [G loss: 0.146058]\n",
      "349 [D loss: 1.278729, acc.: 50.00%] [G loss: 0.149069]\n",
      "350 [D loss: 1.301042, acc.: 50.00%] [G loss: 0.144626]\n",
      "351 [D loss: 1.274814, acc.: 50.00%] [G loss: 0.144002]\n",
      "352 [D loss: 1.257291, acc.: 50.00%] [G loss: 0.149065]\n",
      "353 [D loss: 1.270769, acc.: 50.00%] [G loss: 0.140498]\n",
      "354 [D loss: 1.227681, acc.: 50.00%] [G loss: 0.143749]\n",
      "355 [D loss: 1.271549, acc.: 50.00%] [G loss: 0.148760]\n",
      "356 [D loss: 1.262155, acc.: 50.00%] [G loss: 0.141400]\n",
      "357 [D loss: 1.254710, acc.: 50.00%] [G loss: 0.141550]\n",
      "358 [D loss: 1.303780, acc.: 50.00%] [G loss: 0.145244]\n",
      "359 [D loss: 1.244449, acc.: 50.00%] [G loss: 0.149025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 [D loss: 1.280960, acc.: 50.00%] [G loss: 0.147367]\n",
      "361 [D loss: 1.270158, acc.: 50.00%] [G loss: 0.156091]\n",
      "362 [D loss: 1.282907, acc.: 50.00%] [G loss: 0.156145]\n",
      "363 [D loss: 1.266995, acc.: 50.00%] [G loss: 0.149058]\n",
      "364 [D loss: 1.294390, acc.: 50.00%] [G loss: 0.144455]\n",
      "365 [D loss: 1.278597, acc.: 50.00%] [G loss: 0.144148]\n",
      "366 [D loss: 1.281391, acc.: 50.00%] [G loss: 0.154842]\n",
      "367 [D loss: 1.266895, acc.: 50.00%] [G loss: 0.141639]\n",
      "368 [D loss: 1.283054, acc.: 50.00%] [G loss: 0.140416]\n",
      "369 [D loss: 1.284154, acc.: 50.00%] [G loss: 0.136395]\n",
      "370 [D loss: 1.252487, acc.: 50.00%] [G loss: 0.142266]\n",
      "371 [D loss: 1.242180, acc.: 50.00%] [G loss: 0.147006]\n",
      "372 [D loss: 1.258936, acc.: 50.00%] [G loss: 0.145261]\n",
      "373 [D loss: 1.272801, acc.: 50.00%] [G loss: 0.150180]\n",
      "374 [D loss: 1.235965, acc.: 50.00%] [G loss: 0.140100]\n",
      "375 [D loss: 1.304179, acc.: 50.00%] [G loss: 0.161018]\n",
      "376 [D loss: 1.231323, acc.: 50.00%] [G loss: 0.145490]\n",
      "377 [D loss: 1.286110, acc.: 50.00%] [G loss: 0.155315]\n",
      "378 [D loss: 1.259830, acc.: 50.00%] [G loss: 0.151297]\n",
      "379 [D loss: 1.301669, acc.: 50.00%] [G loss: 0.144504]\n",
      "380 [D loss: 1.319554, acc.: 50.00%] [G loss: 0.154528]\n",
      "381 [D loss: 1.304448, acc.: 50.00%] [G loss: 0.144089]\n",
      "382 [D loss: 1.284911, acc.: 50.00%] [G loss: 0.152057]\n",
      "383 [D loss: 1.292894, acc.: 50.00%] [G loss: 0.139537]\n",
      "384 [D loss: 1.282535, acc.: 50.00%] [G loss: 0.151569]\n",
      "385 [D loss: 1.278379, acc.: 50.00%] [G loss: 0.151412]\n",
      "386 [D loss: 1.251635, acc.: 50.00%] [G loss: 0.162597]\n",
      "387 [D loss: 1.268821, acc.: 50.00%] [G loss: 0.147480]\n",
      "388 [D loss: 1.286307, acc.: 50.00%] [G loss: 0.140572]\n",
      "389 [D loss: 1.372846, acc.: 50.00%] [G loss: 0.155297]\n",
      "390 [D loss: 1.283033, acc.: 50.00%] [G loss: 0.144033]\n",
      "391 [D loss: 1.287964, acc.: 50.00%] [G loss: 0.143162]\n",
      "392 [D loss: 1.265867, acc.: 50.00%] [G loss: 0.153305]\n",
      "393 [D loss: 1.255079, acc.: 50.00%] [G loss: 0.152150]\n",
      "394 [D loss: 1.261613, acc.: 50.00%] [G loss: 0.153654]\n",
      "395 [D loss: 1.291441, acc.: 50.00%] [G loss: 0.140867]\n",
      "396 [D loss: 1.327944, acc.: 50.00%] [G loss: 0.139444]\n",
      "397 [D loss: 1.303316, acc.: 50.00%] [G loss: 0.146749]\n",
      "398 [D loss: 1.297259, acc.: 50.00%] [G loss: 0.153270]\n",
      "399 [D loss: 1.265156, acc.: 50.00%] [G loss: 0.152555]\n",
      "400 [D loss: 1.294083, acc.: 50.00%] [G loss: 0.149551]\n",
      "401 [D loss: 1.267765, acc.: 50.00%] [G loss: 0.147967]\n",
      "402 [D loss: 1.296466, acc.: 50.00%] [G loss: 0.143482]\n",
      "403 [D loss: 1.260942, acc.: 50.00%] [G loss: 0.147627]\n",
      "404 [D loss: 1.281567, acc.: 50.00%] [G loss: 0.144885]\n",
      "405 [D loss: 1.279194, acc.: 50.00%] [G loss: 0.147837]\n",
      "406 [D loss: 1.287173, acc.: 50.00%] [G loss: 0.145929]\n",
      "407 [D loss: 1.267000, acc.: 50.00%] [G loss: 0.147946]\n",
      "408 [D loss: 1.233381, acc.: 50.00%] [G loss: 0.141393]\n",
      "409 [D loss: 1.246509, acc.: 50.00%] [G loss: 0.145759]\n",
      "410 [D loss: 1.284157, acc.: 50.00%] [G loss: 0.148700]\n",
      "411 [D loss: 1.258352, acc.: 50.00%] [G loss: 0.142748]\n",
      "412 [D loss: 1.290275, acc.: 50.00%] [G loss: 0.154611]\n",
      "413 [D loss: 1.297775, acc.: 50.00%] [G loss: 0.146232]\n",
      "414 [D loss: 1.265447, acc.: 50.00%] [G loss: 0.151341]\n",
      "415 [D loss: 1.263489, acc.: 50.00%] [G loss: 0.161705]\n",
      "416 [D loss: 1.310144, acc.: 50.00%] [G loss: 0.158073]\n",
      "417 [D loss: 1.255722, acc.: 50.00%] [G loss: 0.148938]\n",
      "418 [D loss: 1.277179, acc.: 50.00%] [G loss: 0.147183]\n",
      "419 [D loss: 1.296174, acc.: 50.00%] [G loss: 0.141045]\n",
      "420 [D loss: 1.287694, acc.: 50.00%] [G loss: 0.145015]\n",
      "421 [D loss: 1.251639, acc.: 50.00%] [G loss: 0.152971]\n",
      "422 [D loss: 1.294879, acc.: 50.00%] [G loss: 0.155774]\n",
      "423 [D loss: 1.241763, acc.: 50.00%] [G loss: 0.148828]\n",
      "424 [D loss: 1.252496, acc.: 50.00%] [G loss: 0.144364]\n",
      "425 [D loss: 1.256971, acc.: 50.00%] [G loss: 0.147708]\n",
      "426 [D loss: 1.254794, acc.: 50.00%] [G loss: 0.145975]\n",
      "427 [D loss: 1.276682, acc.: 50.00%] [G loss: 0.142793]\n",
      "428 [D loss: 1.245431, acc.: 50.00%] [G loss: 0.145796]\n",
      "429 [D loss: 1.305435, acc.: 50.00%] [G loss: 0.155402]\n",
      "430 [D loss: 1.236630, acc.: 50.00%] [G loss: 0.147694]\n",
      "431 [D loss: 1.257331, acc.: 50.00%] [G loss: 0.149939]\n",
      "432 [D loss: 1.263985, acc.: 50.00%] [G loss: 0.154051]\n",
      "433 [D loss: 1.283640, acc.: 50.00%] [G loss: 0.156745]\n",
      "434 [D loss: 1.278223, acc.: 50.00%] [G loss: 0.163064]\n",
      "435 [D loss: 1.279022, acc.: 50.00%] [G loss: 0.144146]\n",
      "436 [D loss: 1.294579, acc.: 50.00%] [G loss: 0.157619]\n",
      "437 [D loss: 1.274663, acc.: 50.00%] [G loss: 0.148847]\n",
      "438 [D loss: 1.244199, acc.: 50.00%] [G loss: 0.142068]\n",
      "439 [D loss: 1.268295, acc.: 50.00%] [G loss: 0.158795]\n",
      "440 [D loss: 1.315533, acc.: 50.00%] [G loss: 0.141925]\n",
      "441 [D loss: 1.251867, acc.: 50.00%] [G loss: 0.156713]\n",
      "442 [D loss: 1.280343, acc.: 50.00%] [G loss: 0.140889]\n",
      "443 [D loss: 1.266411, acc.: 50.00%] [G loss: 0.148076]\n",
      "444 [D loss: 1.249338, acc.: 50.00%] [G loss: 0.162162]\n",
      "445 [D loss: 1.249778, acc.: 50.00%] [G loss: 0.154283]\n",
      "446 [D loss: 1.313891, acc.: 50.00%] [G loss: 0.151839]\n",
      "447 [D loss: 1.291040, acc.: 50.00%] [G loss: 0.155229]\n",
      "448 [D loss: 1.288573, acc.: 50.00%] [G loss: 0.154831]\n",
      "449 [D loss: 1.286382, acc.: 50.00%] [G loss: 0.146714]\n",
      "450 [D loss: 1.290594, acc.: 50.00%] [G loss: 0.147018]\n",
      "451 [D loss: 1.313313, acc.: 50.00%] [G loss: 0.154790]\n",
      "452 [D loss: 1.281597, acc.: 50.00%] [G loss: 0.143154]\n",
      "453 [D loss: 1.285886, acc.: 50.00%] [G loss: 0.150045]\n",
      "454 [D loss: 1.261895, acc.: 50.00%] [G loss: 0.141530]\n",
      "455 [D loss: 1.286110, acc.: 50.00%] [G loss: 0.145435]\n",
      "456 [D loss: 1.247533, acc.: 50.00%] [G loss: 0.150559]\n",
      "457 [D loss: 1.256752, acc.: 50.00%] [G loss: 0.161817]\n",
      "458 [D loss: 1.236804, acc.: 50.00%] [G loss: 0.145200]\n",
      "459 [D loss: 1.238851, acc.: 50.00%] [G loss: 0.147209]\n",
      "460 [D loss: 1.255585, acc.: 50.00%] [G loss: 0.147424]\n",
      "461 [D loss: 1.274158, acc.: 50.00%] [G loss: 0.139117]\n",
      "462 [D loss: 1.285352, acc.: 50.00%] [G loss: 0.145173]\n",
      "463 [D loss: 1.309235, acc.: 50.00%] [G loss: 0.153390]\n",
      "464 [D loss: 1.216155, acc.: 50.00%] [G loss: 0.166712]\n",
      "465 [D loss: 1.262327, acc.: 50.00%] [G loss: 0.160759]\n",
      "466 [D loss: 1.285746, acc.: 50.00%] [G loss: 0.150071]\n",
      "467 [D loss: 1.253289, acc.: 50.00%] [G loss: 0.151370]\n",
      "468 [D loss: 1.250506, acc.: 50.00%] [G loss: 0.145955]\n",
      "469 [D loss: 1.294598, acc.: 50.00%] [G loss: 0.149768]\n",
      "470 [D loss: 1.276745, acc.: 50.00%] [G loss: 0.162744]\n",
      "471 [D loss: 1.296111, acc.: 50.00%] [G loss: 0.152306]\n",
      "472 [D loss: 1.266636, acc.: 50.00%] [G loss: 0.151338]\n",
      "473 [D loss: 1.334042, acc.: 50.00%] [G loss: 0.150645]\n",
      "474 [D loss: 1.313290, acc.: 50.00%] [G loss: 0.152679]\n",
      "475 [D loss: 1.279642, acc.: 50.00%] [G loss: 0.134536]\n",
      "476 [D loss: 1.263811, acc.: 50.00%] [G loss: 0.147226]\n",
      "477 [D loss: 1.258836, acc.: 50.00%] [G loss: 0.150380]\n",
      "478 [D loss: 1.228557, acc.: 50.00%] [G loss: 0.145538]\n",
      "479 [D loss: 1.262453, acc.: 50.00%] [G loss: 0.153207]\n",
      "480 [D loss: 1.248541, acc.: 50.00%] [G loss: 0.144317]\n",
      "481 [D loss: 1.301701, acc.: 50.00%] [G loss: 0.142949]\n",
      "482 [D loss: 1.286047, acc.: 50.00%] [G loss: 0.149051]\n",
      "483 [D loss: 1.269161, acc.: 50.00%] [G loss: 0.156256]\n",
      "484 [D loss: 1.245980, acc.: 50.00%] [G loss: 0.171601]\n",
      "485 [D loss: 1.262002, acc.: 50.00%] [G loss: 0.160289]\n",
      "486 [D loss: 1.291152, acc.: 50.00%] [G loss: 0.145885]\n",
      "487 [D loss: 1.320025, acc.: 50.00%] [G loss: 0.143932]\n",
      "488 [D loss: 1.324310, acc.: 50.00%] [G loss: 0.148678]\n",
      "489 [D loss: 1.245414, acc.: 50.00%] [G loss: 0.148258]\n",
      "490 [D loss: 1.274855, acc.: 50.00%] [G loss: 0.155164]\n",
      "491 [D loss: 1.296613, acc.: 50.00%] [G loss: 0.145617]\n",
      "492 [D loss: 1.269394, acc.: 50.00%] [G loss: 0.154366]\n",
      "493 [D loss: 1.271942, acc.: 50.00%] [G loss: 0.151912]\n",
      "494 [D loss: 1.252465, acc.: 50.00%] [G loss: 0.146260]\n",
      "495 [D loss: 1.235935, acc.: 50.00%] [G loss: 0.152134]\n",
      "496 [D loss: 1.262692, acc.: 50.00%] [G loss: 0.151075]\n",
      "497 [D loss: 1.253441, acc.: 50.00%] [G loss: 0.144635]\n",
      "498 [D loss: 1.257373, acc.: 50.00%] [G loss: 0.171427]\n",
      "499 [D loss: 1.232446, acc.: 50.00%] [G loss: 0.148642]\n",
      "500 [D loss: 1.314431, acc.: 50.00%] [G loss: 0.149174]\n",
      "501 [D loss: 1.288629, acc.: 50.00%] [G loss: 0.154438]\n",
      "502 [D loss: 1.309952, acc.: 50.00%] [G loss: 0.160757]\n",
      "503 [D loss: 1.286119, acc.: 50.00%] [G loss: 0.141503]\n",
      "504 [D loss: 1.280688, acc.: 50.00%] [G loss: 0.170827]\n",
      "505 [D loss: 1.292540, acc.: 50.00%] [G loss: 0.146118]\n",
      "506 [D loss: 1.280729, acc.: 50.00%] [G loss: 0.152662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507 [D loss: 1.300934, acc.: 50.00%] [G loss: 0.167985]\n",
      "508 [D loss: 1.285643, acc.: 50.00%] [G loss: 0.139546]\n",
      "509 [D loss: 1.323777, acc.: 50.00%] [G loss: 0.137391]\n",
      "510 [D loss: 1.292312, acc.: 50.00%] [G loss: 0.135971]\n",
      "511 [D loss: 1.298753, acc.: 50.00%] [G loss: 0.153370]\n",
      "512 [D loss: 1.260618, acc.: 50.00%] [G loss: 0.152341]\n",
      "513 [D loss: 1.237642, acc.: 50.00%] [G loss: 0.147192]\n",
      "514 [D loss: 1.281277, acc.: 50.00%] [G loss: 0.147510]\n",
      "515 [D loss: 1.255839, acc.: 50.00%] [G loss: 0.163665]\n",
      "516 [D loss: 1.266855, acc.: 50.00%] [G loss: 0.148340]\n",
      "517 [D loss: 1.279294, acc.: 50.00%] [G loss: 0.157637]\n",
      "518 [D loss: 1.258950, acc.: 50.00%] [G loss: 0.159106]\n",
      "519 [D loss: 1.290887, acc.: 50.00%] [G loss: 0.146183]\n",
      "520 [D loss: 1.304037, acc.: 50.00%] [G loss: 0.144007]\n",
      "521 [D loss: 1.252163, acc.: 50.00%] [G loss: 0.153089]\n",
      "522 [D loss: 1.273152, acc.: 50.00%] [G loss: 0.161849]\n",
      "523 [D loss: 1.265572, acc.: 50.00%] [G loss: 0.153743]\n",
      "524 [D loss: 1.259629, acc.: 50.00%] [G loss: 0.158474]\n",
      "525 [D loss: 1.309787, acc.: 50.00%] [G loss: 0.146103]\n",
      "526 [D loss: 1.253864, acc.: 50.00%] [G loss: 0.149305]\n",
      "527 [D loss: 1.285848, acc.: 50.00%] [G loss: 0.156958]\n",
      "528 [D loss: 1.225052, acc.: 50.00%] [G loss: 0.146970]\n",
      "529 [D loss: 1.264415, acc.: 50.00%] [G loss: 0.149472]\n",
      "530 [D loss: 1.272645, acc.: 50.00%] [G loss: 0.147151]\n",
      "531 [D loss: 1.255718, acc.: 50.00%] [G loss: 0.151945]\n",
      "532 [D loss: 1.286147, acc.: 50.00%] [G loss: 0.144586]\n",
      "533 [D loss: 1.291598, acc.: 50.00%] [G loss: 0.149949]\n",
      "534 [D loss: 1.275489, acc.: 50.00%] [G loss: 0.169698]\n",
      "535 [D loss: 1.267077, acc.: 50.00%] [G loss: 0.155511]\n",
      "536 [D loss: 1.263807, acc.: 50.00%] [G loss: 0.161271]\n",
      "537 [D loss: 1.258201, acc.: 50.00%] [G loss: 0.149399]\n",
      "538 [D loss: 1.270127, acc.: 50.00%] [G loss: 0.162657]\n",
      "539 [D loss: 1.270610, acc.: 50.00%] [G loss: 0.136641]\n",
      "540 [D loss: 1.264065, acc.: 50.00%] [G loss: 0.147206]\n",
      "541 [D loss: 1.271742, acc.: 50.00%] [G loss: 0.138108]\n",
      "542 [D loss: 1.253732, acc.: 50.00%] [G loss: 0.162598]\n",
      "543 [D loss: 1.237627, acc.: 50.00%] [G loss: 0.147391]\n",
      "544 [D loss: 1.243599, acc.: 50.00%] [G loss: 0.173177]\n",
      "545 [D loss: 1.239447, acc.: 50.00%] [G loss: 0.145390]\n",
      "546 [D loss: 1.269461, acc.: 50.00%] [G loss: 0.147771]\n",
      "547 [D loss: 1.276590, acc.: 50.00%] [G loss: 0.159362]\n",
      "548 [D loss: 1.281363, acc.: 50.00%] [G loss: 0.146894]\n",
      "549 [D loss: 1.259614, acc.: 50.00%] [G loss: 0.152504]\n",
      "550 [D loss: 1.262834, acc.: 50.00%] [G loss: 0.152620]\n",
      "551 [D loss: 1.264729, acc.: 50.00%] [G loss: 0.149280]\n",
      "552 [D loss: 1.281664, acc.: 50.00%] [G loss: 0.149880]\n",
      "553 [D loss: 1.263111, acc.: 50.00%] [G loss: 0.161170]\n",
      "554 [D loss: 1.286940, acc.: 50.00%] [G loss: 0.143922]\n",
      "555 [D loss: 1.284123, acc.: 50.00%] [G loss: 0.156704]\n",
      "556 [D loss: 1.267390, acc.: 50.00%] [G loss: 0.156618]\n",
      "557 [D loss: 1.262796, acc.: 50.00%] [G loss: 0.146437]\n",
      "558 [D loss: 1.274211, acc.: 50.00%] [G loss: 0.149738]\n",
      "559 [D loss: 1.280162, acc.: 50.00%] [G loss: 0.158533]\n",
      "560 [D loss: 1.276856, acc.: 50.00%] [G loss: 0.151762]\n",
      "561 [D loss: 1.267575, acc.: 50.00%] [G loss: 0.159613]\n",
      "562 [D loss: 1.260980, acc.: 50.00%] [G loss: 0.166687]\n",
      "563 [D loss: 1.266637, acc.: 50.00%] [G loss: 0.164288]\n",
      "564 [D loss: 1.271894, acc.: 50.00%] [G loss: 0.146952]\n",
      "565 [D loss: 1.248612, acc.: 50.00%] [G loss: 0.142075]\n",
      "566 [D loss: 1.316682, acc.: 50.00%] [G loss: 0.161147]\n",
      "567 [D loss: 1.260693, acc.: 50.00%] [G loss: 0.147219]\n",
      "568 [D loss: 1.279989, acc.: 50.00%] [G loss: 0.153446]\n",
      "569 [D loss: 1.266263, acc.: 50.00%] [G loss: 0.149376]\n",
      "570 [D loss: 1.236037, acc.: 50.00%] [G loss: 0.158890]\n",
      "571 [D loss: 1.227039, acc.: 50.00%] [G loss: 0.147189]\n",
      "572 [D loss: 1.288430, acc.: 50.00%] [G loss: 0.156203]\n",
      "573 [D loss: 1.248622, acc.: 50.00%] [G loss: 0.149244]\n",
      "574 [D loss: 1.265013, acc.: 50.00%] [G loss: 0.150395]\n",
      "575 [D loss: 1.273678, acc.: 50.00%] [G loss: 0.155052]\n",
      "576 [D loss: 1.270733, acc.: 50.00%] [G loss: 0.159062]\n",
      "577 [D loss: 1.295174, acc.: 50.00%] [G loss: 0.153571]\n",
      "578 [D loss: 1.274709, acc.: 50.00%] [G loss: 0.163675]\n",
      "579 [D loss: 1.245942, acc.: 50.00%] [G loss: 0.164703]\n",
      "580 [D loss: 1.268901, acc.: 50.00%] [G loss: 0.143874]\n",
      "581 [D loss: 1.261722, acc.: 50.00%] [G loss: 0.143520]\n",
      "582 [D loss: 1.269045, acc.: 50.00%] [G loss: 0.153576]\n",
      "583 [D loss: 1.233779, acc.: 50.00%] [G loss: 0.155909]\n",
      "584 [D loss: 1.227149, acc.: 50.00%] [G loss: 0.161361]\n",
      "585 [D loss: 1.230243, acc.: 50.00%] [G loss: 0.160302]\n",
      "586 [D loss: 1.247519, acc.: 50.00%] [G loss: 0.152004]\n",
      "587 [D loss: 1.289919, acc.: 50.00%] [G loss: 0.162233]\n",
      "588 [D loss: 1.242822, acc.: 50.00%] [G loss: 0.145159]\n",
      "589 [D loss: 1.258559, acc.: 50.00%] [G loss: 0.161347]\n",
      "590 [D loss: 1.291887, acc.: 50.00%] [G loss: 0.159404]\n",
      "591 [D loss: 1.244621, acc.: 50.00%] [G loss: 0.149578]\n",
      "592 [D loss: 1.250453, acc.: 50.00%] [G loss: 0.156750]\n",
      "593 [D loss: 1.276251, acc.: 50.00%] [G loss: 0.155398]\n",
      "594 [D loss: 1.245569, acc.: 50.00%] [G loss: 0.150763]\n",
      "595 [D loss: 1.267907, acc.: 50.00%] [G loss: 0.147987]\n",
      "596 [D loss: 1.232487, acc.: 50.00%] [G loss: 0.161037]\n",
      "597 [D loss: 1.255472, acc.: 50.00%] [G loss: 0.161788]\n",
      "598 [D loss: 1.224938, acc.: 50.00%] [G loss: 0.141041]\n",
      "599 [D loss: 1.249280, acc.: 50.00%] [G loss: 0.145978]\n",
      "600 [D loss: 1.252597, acc.: 50.00%] [G loss: 0.156175]\n",
      "601 [D loss: 1.240556, acc.: 50.00%] [G loss: 0.153126]\n",
      "602 [D loss: 1.207623, acc.: 50.00%] [G loss: 0.160154]\n",
      "603 [D loss: 1.289590, acc.: 50.00%] [G loss: 0.156630]\n",
      "604 [D loss: 1.265143, acc.: 50.00%] [G loss: 0.157621]\n",
      "605 [D loss: 1.282078, acc.: 50.00%] [G loss: 0.149837]\n",
      "606 [D loss: 1.244982, acc.: 50.00%] [G loss: 0.147805]\n",
      "607 [D loss: 1.279713, acc.: 50.00%] [G loss: 0.163111]\n",
      "608 [D loss: 1.271736, acc.: 50.00%] [G loss: 0.173370]\n",
      "609 [D loss: 1.274429, acc.: 50.00%] [G loss: 0.143093]\n",
      "610 [D loss: 1.279799, acc.: 50.00%] [G loss: 0.145554]\n",
      "611 [D loss: 1.286208, acc.: 50.00%] [G loss: 0.155757]\n",
      "612 [D loss: 1.254107, acc.: 50.00%] [G loss: 0.154199]\n",
      "613 [D loss: 1.272167, acc.: 50.00%] [G loss: 0.151655]\n",
      "614 [D loss: 1.242277, acc.: 50.00%] [G loss: 0.158453]\n",
      "615 [D loss: 1.244914, acc.: 50.00%] [G loss: 0.157744]\n",
      "616 [D loss: 1.167961, acc.: 50.00%] [G loss: 0.163579]\n",
      "617 [D loss: 1.276495, acc.: 50.00%] [G loss: 0.147362]\n",
      "618 [D loss: 1.224935, acc.: 50.00%] [G loss: 0.145304]\n",
      "619 [D loss: 1.265572, acc.: 50.00%] [G loss: 0.157308]\n",
      "620 [D loss: 1.252349, acc.: 50.00%] [G loss: 0.152802]\n",
      "621 [D loss: 1.251548, acc.: 50.00%] [G loss: 0.150346]\n",
      "622 [D loss: 1.258357, acc.: 50.00%] [G loss: 0.158083]\n",
      "623 [D loss: 1.266428, acc.: 50.00%] [G loss: 0.145736]\n",
      "624 [D loss: 1.224804, acc.: 50.00%] [G loss: 0.163154]\n",
      "625 [D loss: 1.254119, acc.: 50.00%] [G loss: 0.162379]\n",
      "626 [D loss: 1.202512, acc.: 50.00%] [G loss: 0.151823]\n",
      "627 [D loss: 1.219555, acc.: 50.00%] [G loss: 0.146845]\n",
      "628 [D loss: 1.259219, acc.: 50.00%] [G loss: 0.147334]\n",
      "629 [D loss: 1.207018, acc.: 50.00%] [G loss: 0.157883]\n",
      "630 [D loss: 1.244953, acc.: 50.00%] [G loss: 0.144230]\n",
      "631 [D loss: 1.252260, acc.: 50.00%] [G loss: 0.149965]\n",
      "632 [D loss: 1.267662, acc.: 50.00%] [G loss: 0.153788]\n",
      "633 [D loss: 1.251772, acc.: 50.00%] [G loss: 0.164563]\n",
      "634 [D loss: 1.233808, acc.: 50.00%] [G loss: 0.160861]\n",
      "635 [D loss: 1.226043, acc.: 50.00%] [G loss: 0.147468]\n",
      "636 [D loss: 1.242869, acc.: 50.00%] [G loss: 0.159145]\n",
      "637 [D loss: 1.240556, acc.: 50.00%] [G loss: 0.152511]\n",
      "638 [D loss: 1.244419, acc.: 50.00%] [G loss: 0.152892]\n",
      "639 [D loss: 1.229824, acc.: 50.00%] [G loss: 0.159512]\n",
      "640 [D loss: 1.217805, acc.: 50.00%] [G loss: 0.153840]\n",
      "641 [D loss: 1.231723, acc.: 50.00%] [G loss: 0.160296]\n",
      "642 [D loss: 1.270108, acc.: 50.00%] [G loss: 0.146771]\n",
      "643 [D loss: 1.211688, acc.: 50.00%] [G loss: 0.156171]\n",
      "644 [D loss: 1.247973, acc.: 50.00%] [G loss: 0.158310]\n",
      "645 [D loss: 1.248211, acc.: 50.00%] [G loss: 0.151097]\n",
      "646 [D loss: 1.228617, acc.: 50.00%] [G loss: 0.164397]\n",
      "647 [D loss: 1.240731, acc.: 50.00%] [G loss: 0.155823]\n",
      "648 [D loss: 1.219864, acc.: 50.00%] [G loss: 0.153186]\n",
      "649 [D loss: 1.249781, acc.: 50.00%] [G loss: 0.151437]\n",
      "650 [D loss: 1.270592, acc.: 50.00%] [G loss: 0.162910]\n",
      "651 [D loss: 1.225332, acc.: 50.00%] [G loss: 0.156128]\n",
      "652 [D loss: 1.235365, acc.: 50.00%] [G loss: 0.155744]\n",
      "653 [D loss: 1.254247, acc.: 50.00%] [G loss: 0.158444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654 [D loss: 1.226105, acc.: 50.00%] [G loss: 0.165290]\n",
      "655 [D loss: 1.235533, acc.: 50.00%] [G loss: 0.156759]\n",
      "656 [D loss: 1.225272, acc.: 50.00%] [G loss: 0.141032]\n",
      "657 [D loss: 1.223979, acc.: 50.00%] [G loss: 0.162021]\n",
      "658 [D loss: 1.276590, acc.: 50.00%] [G loss: 0.143123]\n",
      "659 [D loss: 1.206403, acc.: 50.00%] [G loss: 0.160376]\n",
      "660 [D loss: 1.260408, acc.: 50.00%] [G loss: 0.159157]\n",
      "661 [D loss: 1.258332, acc.: 50.00%] [G loss: 0.164065]\n",
      "662 [D loss: 1.222783, acc.: 50.00%] [G loss: 0.163157]\n",
      "663 [D loss: 1.242417, acc.: 50.00%] [G loss: 0.149770]\n",
      "664 [D loss: 1.268168, acc.: 50.00%] [G loss: 0.151351]\n",
      "665 [D loss: 1.260299, acc.: 50.00%] [G loss: 0.166296]\n",
      "666 [D loss: 1.199688, acc.: 50.00%] [G loss: 0.171249]\n",
      "667 [D loss: 1.254137, acc.: 50.00%] [G loss: 0.151925]\n",
      "668 [D loss: 1.243309, acc.: 50.00%] [G loss: 0.151182]\n",
      "669 [D loss: 1.263838, acc.: 50.00%] [G loss: 0.152332]\n",
      "670 [D loss: 1.246006, acc.: 50.00%] [G loss: 0.156324]\n",
      "671 [D loss: 1.234976, acc.: 50.00%] [G loss: 0.152673]\n",
      "672 [D loss: 1.240314, acc.: 50.00%] [G loss: 0.149464]\n",
      "673 [D loss: 1.212695, acc.: 50.00%] [G loss: 0.151404]\n",
      "674 [D loss: 1.258752, acc.: 50.00%] [G loss: 0.160559]\n",
      "675 [D loss: 1.238626, acc.: 50.00%] [G loss: 0.160295]\n",
      "676 [D loss: 1.257424, acc.: 50.00%] [G loss: 0.164647]\n",
      "677 [D loss: 1.273960, acc.: 50.00%] [G loss: 0.149014]\n",
      "678 [D loss: 1.216920, acc.: 50.00%] [G loss: 0.153886]\n",
      "679 [D loss: 1.260928, acc.: 50.00%] [G loss: 0.152897]\n",
      "680 [D loss: 1.230582, acc.: 50.00%] [G loss: 0.152187]\n",
      "681 [D loss: 1.213208, acc.: 50.00%] [G loss: 0.147985]\n",
      "682 [D loss: 1.219516, acc.: 50.00%] [G loss: 0.150713]\n",
      "683 [D loss: 1.266548, acc.: 50.00%] [G loss: 0.147608]\n",
      "684 [D loss: 1.248008, acc.: 50.00%] [G loss: 0.157351]\n",
      "685 [D loss: 1.194981, acc.: 50.00%] [G loss: 0.164581]\n",
      "686 [D loss: 1.238441, acc.: 50.00%] [G loss: 0.156928]\n",
      "687 [D loss: 1.231159, acc.: 50.00%] [G loss: 0.166179]\n",
      "688 [D loss: 1.270996, acc.: 50.00%] [G loss: 0.152884]\n",
      "689 [D loss: 1.259498, acc.: 50.00%] [G loss: 0.155141]\n",
      "690 [D loss: 1.251716, acc.: 50.00%] [G loss: 0.149909]\n",
      "691 [D loss: 1.242898, acc.: 50.00%] [G loss: 0.156606]\n",
      "692 [D loss: 1.211621, acc.: 50.00%] [G loss: 0.153047]\n",
      "693 [D loss: 1.257236, acc.: 50.00%] [G loss: 0.161761]\n",
      "694 [D loss: 1.234560, acc.: 50.00%] [G loss: 0.155964]\n",
      "695 [D loss: 1.266619, acc.: 50.00%] [G loss: 0.155779]\n",
      "696 [D loss: 1.266105, acc.: 50.00%] [G loss: 0.149544]\n",
      "697 [D loss: 1.258412, acc.: 50.00%] [G loss: 0.161695]\n",
      "698 [D loss: 1.203323, acc.: 50.00%] [G loss: 0.158093]\n",
      "699 [D loss: 1.213129, acc.: 50.00%] [G loss: 0.162568]\n",
      "700 [D loss: 1.247756, acc.: 50.00%] [G loss: 0.159501]\n",
      "701 [D loss: 1.243245, acc.: 50.00%] [G loss: 0.154006]\n",
      "702 [D loss: 1.258169, acc.: 50.00%] [G loss: 0.150207]\n",
      "703 [D loss: 1.212680, acc.: 50.00%] [G loss: 0.164966]\n",
      "704 [D loss: 1.242642, acc.: 50.00%] [G loss: 0.154501]\n",
      "705 [D loss: 1.221383, acc.: 50.00%] [G loss: 0.163128]\n",
      "706 [D loss: 1.263826, acc.: 50.00%] [G loss: 0.159789]\n",
      "707 [D loss: 1.286130, acc.: 50.00%] [G loss: 0.143995]\n",
      "708 [D loss: 1.235557, acc.: 50.00%] [G loss: 0.155709]\n",
      "709 [D loss: 1.226035, acc.: 50.00%] [G loss: 0.144615]\n",
      "710 [D loss: 1.206750, acc.: 50.00%] [G loss: 0.164794]\n",
      "711 [D loss: 1.237123, acc.: 50.00%] [G loss: 0.148960]\n",
      "712 [D loss: 1.205667, acc.: 50.00%] [G loss: 0.166577]\n",
      "713 [D loss: 1.216816, acc.: 50.00%] [G loss: 0.158414]\n",
      "714 [D loss: 1.253406, acc.: 50.00%] [G loss: 0.154500]\n",
      "715 [D loss: 1.283387, acc.: 50.00%] [G loss: 0.142102]\n",
      "716 [D loss: 1.220796, acc.: 50.00%] [G loss: 0.160268]\n",
      "717 [D loss: 1.231595, acc.: 50.00%] [G loss: 0.163645]\n",
      "718 [D loss: 1.243813, acc.: 50.00%] [G loss: 0.153565]\n",
      "719 [D loss: 1.287334, acc.: 50.00%] [G loss: 0.170234]\n",
      "720 [D loss: 1.232238, acc.: 50.00%] [G loss: 0.161896]\n",
      "721 [D loss: 1.244156, acc.: 50.00%] [G loss: 0.159251]\n",
      "722 [D loss: 1.292703, acc.: 50.00%] [G loss: 0.149213]\n",
      "723 [D loss: 1.253566, acc.: 50.00%] [G loss: 0.160447]\n",
      "724 [D loss: 1.249029, acc.: 50.00%] [G loss: 0.164315]\n",
      "725 [D loss: 1.272544, acc.: 50.00%] [G loss: 0.151611]\n",
      "726 [D loss: 1.236520, acc.: 50.00%] [G loss: 0.152139]\n",
      "727 [D loss: 1.261620, acc.: 50.00%] [G loss: 0.161840]\n",
      "728 [D loss: 1.197837, acc.: 50.00%] [G loss: 0.168836]\n",
      "729 [D loss: 1.282918, acc.: 50.00%] [G loss: 0.155224]\n",
      "730 [D loss: 1.261339, acc.: 50.00%] [G loss: 0.145306]\n",
      "731 [D loss: 1.228993, acc.: 50.00%] [G loss: 0.159697]\n",
      "732 [D loss: 1.228834, acc.: 50.00%] [G loss: 0.149522]\n",
      "733 [D loss: 1.233995, acc.: 50.00%] [G loss: 0.153299]\n",
      "734 [D loss: 1.239262, acc.: 50.00%] [G loss: 0.181759]\n",
      "735 [D loss: 1.243562, acc.: 50.00%] [G loss: 0.168910]\n",
      "736 [D loss: 1.255069, acc.: 50.00%] [G loss: 0.154612]\n",
      "737 [D loss: 1.280158, acc.: 50.00%] [G loss: 0.155277]\n",
      "738 [D loss: 1.199080, acc.: 50.00%] [G loss: 0.146548]\n",
      "739 [D loss: 1.227806, acc.: 50.00%] [G loss: 0.148665]\n",
      "740 [D loss: 1.254985, acc.: 50.00%] [G loss: 0.150393]\n",
      "741 [D loss: 1.179534, acc.: 50.00%] [G loss: 0.165511]\n",
      "742 [D loss: 1.242307, acc.: 50.00%] [G loss: 0.157119]\n",
      "743 [D loss: 1.259787, acc.: 50.00%] [G loss: 0.163646]\n",
      "744 [D loss: 1.211581, acc.: 50.00%] [G loss: 0.155860]\n",
      "745 [D loss: 1.243445, acc.: 50.00%] [G loss: 0.151320]\n",
      "746 [D loss: 1.224455, acc.: 50.00%] [G loss: 0.170059]\n",
      "747 [D loss: 1.205465, acc.: 50.00%] [G loss: 0.152111]\n",
      "748 [D loss: 1.214657, acc.: 50.00%] [G loss: 0.154658]\n",
      "749 [D loss: 1.221684, acc.: 50.00%] [G loss: 0.152382]\n",
      "750 [D loss: 1.238283, acc.: 50.00%] [G loss: 0.166776]\n",
      "751 [D loss: 1.211928, acc.: 50.00%] [G loss: 0.160408]\n",
      "752 [D loss: 1.245552, acc.: 50.00%] [G loss: 0.159565]\n",
      "753 [D loss: 1.243295, acc.: 50.00%] [G loss: 0.154389]\n",
      "754 [D loss: 1.228474, acc.: 50.00%] [G loss: 0.158474]\n",
      "755 [D loss: 1.208904, acc.: 50.00%] [G loss: 0.171850]\n",
      "756 [D loss: 1.228887, acc.: 50.00%] [G loss: 0.150090]\n",
      "757 [D loss: 1.229682, acc.: 50.00%] [G loss: 0.170712]\n",
      "758 [D loss: 1.267195, acc.: 50.00%] [G loss: 0.166195]\n",
      "759 [D loss: 1.219963, acc.: 50.00%] [G loss: 0.151953]\n",
      "760 [D loss: 1.226679, acc.: 50.00%] [G loss: 0.153668]\n",
      "761 [D loss: 1.207914, acc.: 50.00%] [G loss: 0.157808]\n",
      "762 [D loss: 1.238652, acc.: 50.00%] [G loss: 0.149190]\n",
      "763 [D loss: 1.217399, acc.: 50.00%] [G loss: 0.160324]\n",
      "764 [D loss: 1.200045, acc.: 50.00%] [G loss: 0.155212]\n",
      "765 [D loss: 1.225567, acc.: 50.00%] [G loss: 0.153192]\n",
      "766 [D loss: 1.242379, acc.: 50.00%] [G loss: 0.169021]\n",
      "767 [D loss: 1.194360, acc.: 50.00%] [G loss: 0.151618]\n",
      "768 [D loss: 1.238673, acc.: 50.00%] [G loss: 0.166812]\n",
      "769 [D loss: 1.245282, acc.: 50.00%] [G loss: 0.152350]\n",
      "770 [D loss: 1.227294, acc.: 50.00%] [G loss: 0.150738]\n",
      "771 [D loss: 1.199748, acc.: 50.00%] [G loss: 0.164501]\n",
      "772 [D loss: 1.238107, acc.: 50.00%] [G loss: 0.163190]\n",
      "773 [D loss: 1.227002, acc.: 50.00%] [G loss: 0.150271]\n",
      "774 [D loss: 1.213366, acc.: 50.00%] [G loss: 0.157129]\n",
      "775 [D loss: 1.218681, acc.: 50.00%] [G loss: 0.167191]\n",
      "776 [D loss: 1.207926, acc.: 50.00%] [G loss: 0.161658]\n",
      "777 [D loss: 1.280622, acc.: 50.00%] [G loss: 0.147437]\n",
      "778 [D loss: 1.254027, acc.: 50.00%] [G loss: 0.159706]\n",
      "779 [D loss: 1.264184, acc.: 50.00%] [G loss: 0.158083]\n",
      "780 [D loss: 1.223612, acc.: 50.00%] [G loss: 0.158808]\n",
      "781 [D loss: 1.236660, acc.: 50.00%] [G loss: 0.150865]\n",
      "782 [D loss: 1.180787, acc.: 50.00%] [G loss: 0.168898]\n",
      "783 [D loss: 1.230316, acc.: 50.00%] [G loss: 0.160588]\n",
      "784 [D loss: 1.239191, acc.: 50.00%] [G loss: 0.147262]\n",
      "785 [D loss: 1.239136, acc.: 50.00%] [G loss: 0.153757]\n",
      "786 [D loss: 1.223936, acc.: 50.00%] [G loss: 0.150880]\n",
      "787 [D loss: 1.233903, acc.: 50.00%] [G loss: 0.160874]\n",
      "788 [D loss: 1.212016, acc.: 50.00%] [G loss: 0.172454]\n",
      "789 [D loss: 1.206638, acc.: 50.00%] [G loss: 0.164557]\n",
      "790 [D loss: 1.232630, acc.: 50.00%] [G loss: 0.154442]\n",
      "791 [D loss: 1.212962, acc.: 50.00%] [G loss: 0.162701]\n",
      "792 [D loss: 1.216035, acc.: 50.00%] [G loss: 0.159548]\n",
      "793 [D loss: 1.245823, acc.: 50.00%] [G loss: 0.161617]\n",
      "794 [D loss: 1.232305, acc.: 50.00%] [G loss: 0.157456]\n",
      "795 [D loss: 1.240991, acc.: 50.00%] [G loss: 0.158877]\n",
      "796 [D loss: 1.217629, acc.: 50.00%] [G loss: 0.149809]\n",
      "797 [D loss: 1.260161, acc.: 50.00%] [G loss: 0.154749]\n",
      "798 [D loss: 1.196191, acc.: 50.00%] [G loss: 0.162815]\n",
      "799 [D loss: 1.199507, acc.: 50.00%] [G loss: 0.163443]\n",
      "800 [D loss: 1.236726, acc.: 50.00%] [G loss: 0.171294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801 [D loss: 1.238474, acc.: 50.00%] [G loss: 0.142958]\n",
      "802 [D loss: 1.224429, acc.: 50.00%] [G loss: 0.150868]\n",
      "803 [D loss: 1.202495, acc.: 50.00%] [G loss: 0.165452]\n",
      "804 [D loss: 1.192999, acc.: 50.00%] [G loss: 0.187066]\n",
      "805 [D loss: 1.259037, acc.: 50.00%] [G loss: 0.152701]\n",
      "806 [D loss: 1.256736, acc.: 50.00%] [G loss: 0.161970]\n",
      "807 [D loss: 1.267005, acc.: 50.00%] [G loss: 0.157839]\n",
      "808 [D loss: 1.239706, acc.: 50.00%] [G loss: 0.169847]\n",
      "809 [D loss: 1.212598, acc.: 50.00%] [G loss: 0.160477]\n",
      "810 [D loss: 1.249415, acc.: 50.00%] [G loss: 0.158476]\n",
      "811 [D loss: 1.253202, acc.: 50.00%] [G loss: 0.153907]\n",
      "812 [D loss: 1.209390, acc.: 50.00%] [G loss: 0.151904]\n",
      "813 [D loss: 1.244630, acc.: 50.00%] [G loss: 0.160293]\n",
      "814 [D loss: 1.238591, acc.: 50.00%] [G loss: 0.166669]\n",
      "815 [D loss: 1.213434, acc.: 50.00%] [G loss: 0.161050]\n",
      "816 [D loss: 1.194543, acc.: 50.00%] [G loss: 0.156842]\n",
      "817 [D loss: 1.198432, acc.: 50.00%] [G loss: 0.153775]\n",
      "818 [D loss: 1.184572, acc.: 50.00%] [G loss: 0.175456]\n",
      "819 [D loss: 1.255239, acc.: 50.00%] [G loss: 0.174443]\n",
      "820 [D loss: 1.246493, acc.: 50.00%] [G loss: 0.170446]\n",
      "821 [D loss: 1.217246, acc.: 50.00%] [G loss: 0.179591]\n",
      "822 [D loss: 1.270598, acc.: 50.00%] [G loss: 0.159031]\n",
      "823 [D loss: 1.279278, acc.: 50.00%] [G loss: 0.150071]\n",
      "824 [D loss: 1.235582, acc.: 50.00%] [G loss: 0.157318]\n",
      "825 [D loss: 1.217732, acc.: 50.00%] [G loss: 0.150806]\n",
      "826 [D loss: 1.192371, acc.: 50.00%] [G loss: 0.165571]\n",
      "827 [D loss: 1.258555, acc.: 50.00%] [G loss: 0.151677]\n",
      "828 [D loss: 1.232390, acc.: 50.00%] [G loss: 0.153953]\n",
      "829 [D loss: 1.246468, acc.: 50.00%] [G loss: 0.162294]\n",
      "830 [D loss: 1.172860, acc.: 50.00%] [G loss: 0.169202]\n",
      "831 [D loss: 1.218990, acc.: 50.00%] [G loss: 0.156045]\n",
      "832 [D loss: 1.224306, acc.: 50.00%] [G loss: 0.164269]\n",
      "833 [D loss: 1.198362, acc.: 50.00%] [G loss: 0.153450]\n",
      "834 [D loss: 1.218515, acc.: 50.00%] [G loss: 0.156794]\n",
      "835 [D loss: 1.262235, acc.: 50.00%] [G loss: 0.156776]\n",
      "836 [D loss: 1.186325, acc.: 50.00%] [G loss: 0.182916]\n",
      "837 [D loss: 1.215098, acc.: 50.00%] [G loss: 0.147813]\n",
      "838 [D loss: 1.217304, acc.: 50.00%] [G loss: 0.148698]\n",
      "839 [D loss: 1.235829, acc.: 50.00%] [G loss: 0.167312]\n",
      "840 [D loss: 1.242041, acc.: 50.00%] [G loss: 0.167569]\n",
      "841 [D loss: 1.239237, acc.: 50.00%] [G loss: 0.166685]\n",
      "842 [D loss: 1.236447, acc.: 50.00%] [G loss: 0.164607]\n",
      "843 [D loss: 1.208151, acc.: 50.00%] [G loss: 0.162195]\n",
      "844 [D loss: 1.256707, acc.: 50.00%] [G loss: 0.166598]\n",
      "845 [D loss: 1.204603, acc.: 50.00%] [G loss: 0.163926]\n",
      "846 [D loss: 1.222337, acc.: 50.00%] [G loss: 0.173192]\n",
      "847 [D loss: 1.239028, acc.: 50.00%] [G loss: 0.146238]\n",
      "848 [D loss: 1.236899, acc.: 50.00%] [G loss: 0.149832]\n",
      "849 [D loss: 1.226075, acc.: 50.00%] [G loss: 0.160707]\n",
      "850 [D loss: 1.240005, acc.: 50.00%] [G loss: 0.175143]\n",
      "851 [D loss: 1.248151, acc.: 50.00%] [G loss: 0.161090]\n",
      "852 [D loss: 1.207412, acc.: 50.00%] [G loss: 0.149328]\n",
      "853 [D loss: 1.215647, acc.: 50.00%] [G loss: 0.159747]\n",
      "854 [D loss: 1.186749, acc.: 50.00%] [G loss: 0.155921]\n",
      "855 [D loss: 1.190039, acc.: 50.00%] [G loss: 0.158006]\n",
      "856 [D loss: 1.185584, acc.: 50.00%] [G loss: 0.162368]\n",
      "857 [D loss: 1.216251, acc.: 50.00%] [G loss: 0.166523]\n",
      "858 [D loss: 1.214568, acc.: 50.00%] [G loss: 0.153154]\n",
      "859 [D loss: 1.194308, acc.: 50.00%] [G loss: 0.162917]\n",
      "860 [D loss: 1.212417, acc.: 50.00%] [G loss: 0.165397]\n",
      "861 [D loss: 1.206236, acc.: 50.00%] [G loss: 0.161843]\n",
      "862 [D loss: 1.194188, acc.: 50.00%] [G loss: 0.163312]\n",
      "863 [D loss: 1.232958, acc.: 50.00%] [G loss: 0.162778]\n",
      "864 [D loss: 1.216223, acc.: 50.00%] [G loss: 0.175342]\n",
      "865 [D loss: 1.235874, acc.: 50.00%] [G loss: 0.169705]\n",
      "866 [D loss: 1.238202, acc.: 50.00%] [G loss: 0.161287]\n",
      "867 [D loss: 1.228571, acc.: 50.00%] [G loss: 0.154745]\n",
      "868 [D loss: 1.224620, acc.: 50.00%] [G loss: 0.148696]\n",
      "869 [D loss: 1.201107, acc.: 50.00%] [G loss: 0.166648]\n",
      "870 [D loss: 1.224068, acc.: 50.00%] [G loss: 0.162913]\n",
      "871 [D loss: 1.180556, acc.: 50.00%] [G loss: 0.157670]\n",
      "872 [D loss: 1.247051, acc.: 50.00%] [G loss: 0.175447]\n",
      "873 [D loss: 1.229041, acc.: 50.00%] [G loss: 0.179925]\n",
      "874 [D loss: 1.227803, acc.: 50.00%] [G loss: 0.159173]\n",
      "875 [D loss: 1.259910, acc.: 50.00%] [G loss: 0.170565]\n",
      "876 [D loss: 1.228829, acc.: 50.00%] [G loss: 0.149377]\n",
      "877 [D loss: 1.198322, acc.: 50.00%] [G loss: 0.159583]\n",
      "878 [D loss: 1.199786, acc.: 50.00%] [G loss: 0.155172]\n",
      "879 [D loss: 1.192853, acc.: 50.00%] [G loss: 0.165210]\n",
      "880 [D loss: 1.166844, acc.: 50.00%] [G loss: 0.176381]\n",
      "881 [D loss: 1.229481, acc.: 50.00%] [G loss: 0.154990]\n",
      "882 [D loss: 1.233749, acc.: 50.00%] [G loss: 0.155701]\n",
      "883 [D loss: 1.213691, acc.: 50.00%] [G loss: 0.176739]\n",
      "884 [D loss: 1.184458, acc.: 50.00%] [G loss: 0.168543]\n",
      "885 [D loss: 1.256799, acc.: 50.00%] [G loss: 0.141021]\n",
      "886 [D loss: 1.235769, acc.: 50.00%] [G loss: 0.155502]\n",
      "887 [D loss: 1.238942, acc.: 50.00%] [G loss: 0.166087]\n",
      "888 [D loss: 1.199265, acc.: 50.00%] [G loss: 0.173978]\n",
      "889 [D loss: 1.192546, acc.: 50.00%] [G loss: 0.163074]\n",
      "890 [D loss: 1.235121, acc.: 50.00%] [G loss: 0.162576]\n",
      "891 [D loss: 1.224511, acc.: 50.00%] [G loss: 0.164138]\n",
      "892 [D loss: 1.213158, acc.: 50.00%] [G loss: 0.151358]\n",
      "893 [D loss: 1.192940, acc.: 50.00%] [G loss: 0.150285]\n",
      "894 [D loss: 1.197346, acc.: 50.00%] [G loss: 0.155228]\n",
      "895 [D loss: 1.173620, acc.: 50.00%] [G loss: 0.174286]\n",
      "896 [D loss: 1.213521, acc.: 50.00%] [G loss: 0.173532]\n",
      "897 [D loss: 1.194220, acc.: 50.00%] [G loss: 0.174876]\n",
      "898 [D loss: 1.245750, acc.: 50.00%] [G loss: 0.158206]\n",
      "899 [D loss: 1.161933, acc.: 50.00%] [G loss: 0.169493]\n",
      "900 [D loss: 1.197424, acc.: 50.00%] [G loss: 0.159491]\n",
      "901 [D loss: 1.268790, acc.: 50.00%] [G loss: 0.158065]\n",
      "902 [D loss: 1.203776, acc.: 50.00%] [G loss: 0.155041]\n",
      "903 [D loss: 1.179229, acc.: 50.00%] [G loss: 0.173164]\n",
      "904 [D loss: 1.208430, acc.: 50.00%] [G loss: 0.177602]\n",
      "905 [D loss: 1.206792, acc.: 50.00%] [G loss: 0.176237]\n",
      "906 [D loss: 1.212294, acc.: 50.00%] [G loss: 0.156610]\n",
      "907 [D loss: 1.243442, acc.: 50.00%] [G loss: 0.164332]\n",
      "908 [D loss: 1.253057, acc.: 50.00%] [G loss: 0.166696]\n",
      "909 [D loss: 1.250883, acc.: 50.00%] [G loss: 0.165790]\n",
      "910 [D loss: 1.228008, acc.: 50.00%] [G loss: 0.160624]\n",
      "911 [D loss: 1.205872, acc.: 50.00%] [G loss: 0.151249]\n",
      "912 [D loss: 1.244575, acc.: 50.00%] [G loss: 0.161840]\n",
      "913 [D loss: 1.165914, acc.: 50.00%] [G loss: 0.163880]\n",
      "914 [D loss: 1.248335, acc.: 50.00%] [G loss: 0.173178]\n",
      "915 [D loss: 1.258094, acc.: 50.00%] [G loss: 0.156415]\n",
      "916 [D loss: 1.267511, acc.: 50.00%] [G loss: 0.153305]\n",
      "917 [D loss: 1.232372, acc.: 50.00%] [G loss: 0.168063]\n",
      "918 [D loss: 1.220336, acc.: 50.00%] [G loss: 0.159814]\n",
      "919 [D loss: 1.265617, acc.: 50.00%] [G loss: 0.176132]\n",
      "920 [D loss: 1.221275, acc.: 50.00%] [G loss: 0.160598]\n",
      "921 [D loss: 1.191198, acc.: 50.00%] [G loss: 0.181603]\n",
      "922 [D loss: 1.244347, acc.: 50.00%] [G loss: 0.159384]\n",
      "923 [D loss: 1.221874, acc.: 50.00%] [G loss: 0.169970]\n",
      "924 [D loss: 1.220427, acc.: 50.00%] [G loss: 0.154773]\n",
      "925 [D loss: 1.234985, acc.: 50.00%] [G loss: 0.162198]\n",
      "926 [D loss: 1.220481, acc.: 50.00%] [G loss: 0.163922]\n",
      "927 [D loss: 1.213086, acc.: 50.00%] [G loss: 0.179866]\n",
      "928 [D loss: 1.206413, acc.: 50.00%] [G loss: 0.163413]\n",
      "929 [D loss: 1.234717, acc.: 50.00%] [G loss: 0.163953]\n",
      "930 [D loss: 1.220465, acc.: 50.00%] [G loss: 0.164428]\n",
      "931 [D loss: 1.234881, acc.: 50.00%] [G loss: 0.171674]\n",
      "932 [D loss: 1.211845, acc.: 50.00%] [G loss: 0.172800]\n",
      "933 [D loss: 1.202062, acc.: 50.00%] [G loss: 0.171237]\n",
      "934 [D loss: 1.210854, acc.: 50.00%] [G loss: 0.138394]\n",
      "935 [D loss: 1.234284, acc.: 50.00%] [G loss: 0.165052]\n",
      "936 [D loss: 1.201223, acc.: 50.00%] [G loss: 0.170407]\n",
      "937 [D loss: 1.212586, acc.: 50.00%] [G loss: 0.161022]\n",
      "938 [D loss: 1.216566, acc.: 50.00%] [G loss: 0.164617]\n",
      "939 [D loss: 1.211216, acc.: 50.00%] [G loss: 0.176383]\n",
      "940 [D loss: 1.250071, acc.: 50.00%] [G loss: 0.160455]\n",
      "941 [D loss: 1.228624, acc.: 50.00%] [G loss: 0.183192]\n",
      "942 [D loss: 1.208562, acc.: 50.00%] [G loss: 0.164369]\n",
      "943 [D loss: 1.224919, acc.: 50.00%] [G loss: 0.157834]\n",
      "944 [D loss: 1.218852, acc.: 50.00%] [G loss: 0.156857]\n",
      "945 [D loss: 1.245384, acc.: 50.00%] [G loss: 0.158112]\n",
      "946 [D loss: 1.208836, acc.: 50.00%] [G loss: 0.167159]\n",
      "947 [D loss: 1.158673, acc.: 50.00%] [G loss: 0.171879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948 [D loss: 1.237245, acc.: 50.00%] [G loss: 0.161446]\n",
      "949 [D loss: 1.231264, acc.: 50.00%] [G loss: 0.161676]\n",
      "950 [D loss: 1.215908, acc.: 50.00%] [G loss: 0.167367]\n",
      "951 [D loss: 1.213404, acc.: 50.00%] [G loss: 0.168252]\n",
      "952 [D loss: 1.230540, acc.: 50.00%] [G loss: 0.154625]\n",
      "953 [D loss: 1.215276, acc.: 50.00%] [G loss: 0.165913]\n",
      "954 [D loss: 1.184784, acc.: 50.00%] [G loss: 0.170434]\n",
      "955 [D loss: 1.229411, acc.: 50.00%] [G loss: 0.166457]\n",
      "956 [D loss: 1.212630, acc.: 50.00%] [G loss: 0.178673]\n",
      "957 [D loss: 1.180664, acc.: 50.00%] [G loss: 0.174339]\n",
      "958 [D loss: 1.233714, acc.: 50.00%] [G loss: 0.161743]\n",
      "959 [D loss: 1.276895, acc.: 50.00%] [G loss: 0.179430]\n",
      "960 [D loss: 1.262033, acc.: 50.00%] [G loss: 0.171348]\n",
      "961 [D loss: 1.244110, acc.: 50.00%] [G loss: 0.194759]\n",
      "962 [D loss: 1.287337, acc.: 50.00%] [G loss: 0.139517]\n",
      "963 [D loss: 1.304054, acc.: 50.00%] [G loss: 0.154328]\n",
      "964 [D loss: 1.246181, acc.: 50.00%] [G loss: 0.158758]\n",
      "965 [D loss: 1.242712, acc.: 50.00%] [G loss: 0.173172]\n",
      "966 [D loss: 1.211151, acc.: 50.00%] [G loss: 0.183427]\n",
      "967 [D loss: 1.213750, acc.: 50.00%] [G loss: 0.164795]\n",
      "968 [D loss: 1.276531, acc.: 50.00%] [G loss: 0.166224]\n",
      "969 [D loss: 1.211829, acc.: 50.00%] [G loss: 0.158171]\n",
      "970 [D loss: 1.201436, acc.: 50.00%] [G loss: 0.165406]\n",
      "971 [D loss: 1.209449, acc.: 50.00%] [G loss: 0.151228]\n",
      "972 [D loss: 1.232488, acc.: 50.00%] [G loss: 0.164506]\n",
      "973 [D loss: 1.209335, acc.: 50.00%] [G loss: 0.172271]\n",
      "974 [D loss: 1.185015, acc.: 50.00%] [G loss: 0.170931]\n",
      "975 [D loss: 1.241197, acc.: 50.00%] [G loss: 0.172686]\n",
      "976 [D loss: 1.202704, acc.: 50.00%] [G loss: 0.177380]\n",
      "977 [D loss: 1.210184, acc.: 50.00%] [G loss: 0.157094]\n",
      "978 [D loss: 1.247865, acc.: 50.00%] [G loss: 0.172551]\n",
      "979 [D loss: 1.203363, acc.: 50.00%] [G loss: 0.167613]\n",
      "980 [D loss: 1.230202, acc.: 50.00%] [G loss: 0.162936]\n",
      "981 [D loss: 1.226417, acc.: 50.00%] [G loss: 0.158839]\n",
      "982 [D loss: 1.200960, acc.: 50.00%] [G loss: 0.176176]\n",
      "983 [D loss: 1.185467, acc.: 50.00%] [G loss: 0.174871]\n",
      "984 [D loss: 1.287119, acc.: 50.00%] [G loss: 0.169952]\n",
      "985 [D loss: 1.208045, acc.: 50.00%] [G loss: 0.180560]\n",
      "986 [D loss: 1.235382, acc.: 50.00%] [G loss: 0.165400]\n",
      "987 [D loss: 1.195224, acc.: 50.00%] [G loss: 0.171627]\n",
      "988 [D loss: 1.215973, acc.: 50.00%] [G loss: 0.171605]\n",
      "989 [D loss: 1.194058, acc.: 50.00%] [G loss: 0.170558]\n",
      "990 [D loss: 1.250819, acc.: 50.00%] [G loss: 0.176209]\n",
      "991 [D loss: 1.199765, acc.: 50.00%] [G loss: 0.167828]\n",
      "992 [D loss: 1.264306, acc.: 50.00%] [G loss: 0.170678]\n",
      "993 [D loss: 1.231012, acc.: 50.00%] [G loss: 0.163245]\n",
      "994 [D loss: 1.250342, acc.: 50.00%] [G loss: 0.169292]\n",
      "995 [D loss: 1.202996, acc.: 50.00%] [G loss: 0.162022]\n",
      "996 [D loss: 1.221293, acc.: 50.00%] [G loss: 0.175152]\n",
      "997 [D loss: 1.243007, acc.: 50.00%] [G loss: 0.157588]\n",
      "998 [D loss: 1.214518, acc.: 50.00%] [G loss: 0.173637]\n",
      "999 [D loss: 1.198900, acc.: 50.00%] [G loss: 0.163082]\n",
      "1000 [D loss: 1.206542, acc.: 50.00%] [G loss: 0.163385]\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(100, network_input, n_notes, n_offset, n_duration)\n",
    "gan.train(X_train=network_input, y_train=[network_output_notes, network_output_offset, network_output_duration], epochs=1000, batch_size=20, sample_interval=100)\n",
    "gan.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B3', 2.5, 8.0], ['G1', 0.0, 3.5], ['D6', 2.25, Fraction(1, 3)], ['5.11', 2.5, 5.75], ['G3', Fraction(333, 1000), 3.0], ['6.11.0', 3.0, 1.5], ['G5', 1.0, 1.75], ['F#6', 1.75, 7.0], ['E5', 3.0, 8.0], ['G4', 2.0, 1.25], ['4.6.7', 3.0, 5.75], ['G6', 2.25, 2.75], ['G3', 0.25, 1.75], ['G1', 2.0, 4.0], ['G#6', 4.5, 8.0], ['G6', 0.0, 1.5], ['G6', 3.0, Fraction(8, 3)], ['G6', 2.0, Fraction(2, 3)], ['G6', 0.5, 3.0], ['G#3', 1.667, 0.75], ['8.9.0', 0.417, 6.0], ['F5', 0.25, 2.0], ['G5', 1.667, 2.25], ['F1', 0.833, 3.0], ['G#6', 0.833, 0.5], ['8.10.1', 0.75, 4.5], ['11.1.6', 3.75, 4.25], ['A5', 1.25, 5.75], ['E-6', 3.0, Fraction(1, 3)], ['4.6.8.11.1', 2.5, Fraction(11, 3)], ['9.10', 2.25, Fraction(2, 3)], ['G4', Fraction(667, 1000), 1.75], ['G4', 0.833, 4.0], ['4.8.11', 2.5, 5.75], ['G2', Fraction(333, 1000), 3.0], ['7.10', 2.5, Fraction(4, 3)], ['G4', 3.0, Fraction(11, 3)], ['G6', 4.0, 0.25], ['D2', 2.0, Fraction(1, 3)], ['E6', 1.667, 3.75], ['G6', 3.75, 4.0], ['B1', 0.0, 3.75], ['6.9.11.2', 2.25, 5.0], ['E5', 4.0, 6.0], ['G6', 2.5, 5.0], ['G4', 0.75, 1.5], ['F6', 0.083, Fraction(8, 3)], ['G5', 1.5, 6.0], ['B-2', 2.5, 0.5], ['G#4', 0.333, Fraction(8, 3)], ['6.7.11.2', 0.417, 5.0], ['4.6', 1.5, 7.0], ['G6', 2.0, 3.0], ['E-2', 0.083, 5.75], ['9.1', 0.333, 4.25], ['F#3', 1.75, 7.0], ['G4', 0.75, 0.25], ['G#6', 2.0, 0.25], ['G4', 1.667, 2.5], ['B3', 0.417, 2.5], ['C7', 3.75, 5.0], ['G1', 0.083, Fraction(8, 3)], ['G5', 0.333, Fraction(11, 3)], ['E-2', 4.5, 8.0], ['G6', 4.0, 3.75], ['G4', 0.333, 2.0], ['G6', 2.5, 2.25], ['4.6', 2.0, 5.75], ['C#5', 1.75, 3.5], ['7.8', 4.5, 7.0], ['E-3', 0.167, 3.75], ['G6', 3.0, 0.0], ['G6', 2.0, 0.75], ['G1', 0.083, 2.0], ['G6', 1.75, 3.0], ['D4', 0.167, 5.75], ['B5', 0.417, 7.0], ['G6', 0.333, 2.75], ['G2', 0.75, Fraction(1, 3)], ['G5', 2.0, Fraction(8, 3)], ['F#6', 0.167, 6.0], ['G#2', 1.75, Fraction(8, 3)], ['F5', Fraction(333, 1000), 2.0], ['A3', 2.25, 4.5], ['8.11.2', 0.25, 4.5], ['G#4', 0.25, 2.75], ['G6', 0.833, 4.0], ['G6', 2.5, 0.75], ['E2', 3.75, 0.5], ['7.9.1', 3.0, Fraction(4, 3)], ['F6', 0.75, 3.75], ['G5', 1.667, 4.5], ['C#7', Fraction(333, 1000), 4.25], ['9.10.2', 0.667, 4.0], ['G5', 3.75, 0.5], ['G4', 2.5, Fraction(1, 3)], ['G#6', 0.25, 3.5], ['F2', 0.25, 4.0], ['G6', 0.333, 0.0], ['G5', Fraction(667, 1000), 2.75]]\n"
     ]
    }
   ],
   "source": [
    "output_pred = gan.generate_notes(notes, possibleNotes, possibleOffsets, possibleDurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.create_midi(output_pred, 'GAN_output_X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_0.hdf5\n",
      "[[[-0.79037344]\n",
      "  [ 0.70460176]\n",
      "  [-0.28947598]\n",
      "  [ 0.8814572 ]\n",
      "  [-0.6107855 ]\n",
      "  [-0.38538986]\n",
      "  [ 0.07783478]\n",
      "  [ 0.41338134]\n",
      "  [-0.8948215 ]\n",
      "  [ 0.7541267 ]\n",
      "  [ 0.42156288]\n",
      "  [ 0.82168484]\n",
      "  [-0.877071  ]\n",
      "  [-0.3693905 ]\n",
      "  [ 0.06191757]\n",
      "  [-0.41833857]\n",
      "  [ 0.6497538 ]\n",
      "  [ 0.9913109 ]\n",
      "  [ 0.9248787 ]\n",
      "  [-0.99073195]\n",
      "  [ 0.75921595]\n",
      "  [-0.38791367]\n",
      "  [ 0.7617763 ]\n",
      "  [-0.08390729]\n",
      "  [ 0.38214526]\n",
      "  [-0.53922236]\n",
      "  [ 0.99005866]\n",
      "  [ 0.86944044]\n",
      "  [ 0.02686271]\n",
      "  [-0.9834003 ]\n",
      "  [-0.44417801]\n",
      "  [ 0.947354  ]\n",
      "  [-0.4138857 ]\n",
      "  [ 0.30625492]\n",
      "  [ 0.8054296 ]\n",
      "  [ 0.8645084 ]\n",
      "  [-0.91852987]\n",
      "  [-0.82418436]\n",
      "  [-0.9886027 ]\n",
      "  [ 0.2925736 ]\n",
      "  [-0.9160985 ]\n",
      "  [ 0.85405934]\n",
      "  [ 0.70144534]\n",
      "  [ 0.9964825 ]\n",
      "  [ 0.19647111]\n",
      "  [ 0.9931008 ]\n",
      "  [-0.90167433]\n",
      "  [ 0.8092278 ]\n",
      "  [ 0.9887396 ]\n",
      "  [ 0.9437407 ]\n",
      "  [-0.97892994]\n",
      "  [-0.27275044]\n",
      "  [-0.42333934]\n",
      "  [-0.60200846]\n",
      "  [ 0.9684587 ]\n",
      "  [-0.89766115]\n",
      "  [ 0.79444194]\n",
      "  [ 0.92340887]\n",
      "  [-0.90745413]\n",
      "  [ 0.9953945 ]\n",
      "  [-0.8830324 ]\n",
      "  [ 0.13331099]\n",
      "  [ 0.7413168 ]\n",
      "  [-0.9614213 ]\n",
      "  [ 0.8233691 ]\n",
      "  [-0.74050635]\n",
      "  [-0.96707815]\n",
      "  [-0.9728913 ]\n",
      "  [-0.7950456 ]\n",
      "  [-0.9703387 ]\n",
      "  [ 0.78709114]\n",
      "  [ 0.67227733]\n",
      "  [-0.99928653]\n",
      "  [ 0.68459535]\n",
      "  [ 0.65246946]\n",
      "  [-0.5170374 ]\n",
      "  [-0.96044797]\n",
      "  [-0.8062148 ]\n",
      "  [ 0.65074384]\n",
      "  [-0.93091863]\n",
      "  [-0.9246078 ]\n",
      "  [-0.46855342]\n",
      "  [ 0.62174976]\n",
      "  [ 0.99147904]\n",
      "  [ 0.43130967]\n",
      "  [-0.28005326]\n",
      "  [ 0.61223364]\n",
      "  [-0.9634402 ]\n",
      "  [-0.86890876]\n",
      "  [-0.76328456]\n",
      "  [ 0.9422742 ]\n",
      "  [-0.92046297]\n",
      "  [-0.10999902]\n",
      "  [ 0.8924944 ]\n",
      "  [ 0.55851746]\n",
      "  [ 0.911865  ]\n",
      "  [-0.9515138 ]\n",
      "  [ 0.8425831 ]\n",
      "  [-0.22400057]\n",
      "  [ 0.33786705]]]\n",
      "['1.4', 'D4', '3.7.10', 'F3', '10.3', '3.4.6', '6.9.11', '9.11', '0.4', 'E-4', '9.11.1', 'F#2', '0.5', '3.5', '6.9', '2.7', 'C4', 'G6', 'G#3', '0.1', 'E-5', '3.4', 'E-5', '5.7.11', '9.10', '11.2', 'G5', 'F2', '6.7.10.11.2', '0.1', '2.6', 'G#6', '2.8', '9', 'E5', 'F#6', '0.3.6', '1.3.4', '0.1', '8.9.0', '0.3.6', 'F#5', 'D3', 'G6', '8', 'G6', '0.3.7', 'E5', 'G5', 'G#5', '0.2', '3.8.9', '2.7', '11', 'G3', '0.4', 'E4', 'G#3', '0.3.7', 'G6', '0.4.7', '7.11', 'E-3', '0.2.6', 'F#2', '1.7', '0.2.5', '0.2.5', '1.3.8', '0.2.5', 'E3', 'C6', '0', 'C7', 'C4', '11.2.5', '0.2.6', '1.3.6', 'C4', '0.3.5', '0.3.5.8', '2.3.7.10', 'C#7', 'G6', '9.11.2', '3.8', 'C#5', '0.2.6', '0.6', '1.5.8', 'G#5', '0.3.5.8', '5.6', 'F5', 'B3', 'G#2', '0.2.7', 'F#4', '4.6', '9.0.3']\n",
      "../output/GAN_1570437586/GAN_output_0\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_10.hdf5\n",
      "[[[-0.1269195 ]\n",
      "  [-0.11799017]\n",
      "  [-0.22955072]\n",
      "  [-0.14480351]\n",
      "  [ 0.9255268 ]\n",
      "  [-0.9392188 ]\n",
      "  [ 0.61440283]\n",
      "  [-0.70031595]\n",
      "  [ 0.95279306]\n",
      "  [ 0.71770614]\n",
      "  [-0.98424464]\n",
      "  [ 0.97181445]\n",
      "  [-0.50113654]\n",
      "  [ 0.65204   ]\n",
      "  [-0.99584585]\n",
      "  [-0.43786445]\n",
      "  [ 0.47736552]\n",
      "  [-0.8700954 ]\n",
      "  [ 0.8993868 ]\n",
      "  [-0.9843583 ]\n",
      "  [ 0.8749829 ]\n",
      "  [ 0.7795756 ]\n",
      "  [ 0.9272417 ]\n",
      "  [ 0.9807596 ]\n",
      "  [ 0.9930848 ]\n",
      "  [ 0.92585516]\n",
      "  [-0.66936505]\n",
      "  [ 0.0589729 ]\n",
      "  [ 0.7879689 ]\n",
      "  [-0.46277156]\n",
      "  [ 0.7137258 ]\n",
      "  [-0.78954166]\n",
      "  [-0.21848153]\n",
      "  [-0.47728285]\n",
      "  [-0.9707016 ]\n",
      "  [ 0.95265067]\n",
      "  [-0.7019597 ]\n",
      "  [-0.65731597]\n",
      "  [-0.69843817]\n",
      "  [-0.09961066]\n",
      "  [-0.500527  ]\n",
      "  [-0.7886332 ]\n",
      "  [-0.9312769 ]\n",
      "  [-0.03828077]\n",
      "  [ 0.5146799 ]\n",
      "  [ 0.7385047 ]\n",
      "  [ 0.9645267 ]\n",
      "  [-0.91216207]\n",
      "  [ 0.9706477 ]\n",
      "  [ 0.94608516]\n",
      "  [ 0.9970652 ]\n",
      "  [-0.6602695 ]\n",
      "  [-0.918419  ]\n",
      "  [-0.876729  ]\n",
      "  [-0.9584715 ]\n",
      "  [-0.85765   ]\n",
      "  [-0.4732313 ]\n",
      "  [-0.4629062 ]\n",
      "  [-0.03448911]\n",
      "  [ 0.73201734]\n",
      "  [ 0.99169695]\n",
      "  [-0.25157467]\n",
      "  [ 0.601495  ]\n",
      "  [ 0.682191  ]\n",
      "  [ 0.80617404]\n",
      "  [-0.5174226 ]\n",
      "  [ 0.26616383]\n",
      "  [-0.684721  ]\n",
      "  [-0.44553047]\n",
      "  [-0.9844279 ]\n",
      "  [-0.93544537]\n",
      "  [-0.74024713]\n",
      "  [ 0.9739189 ]\n",
      "  [ 0.8512903 ]\n",
      "  [-0.8369508 ]\n",
      "  [ 0.0566584 ]\n",
      "  [-0.98002267]\n",
      "  [-0.46164224]\n",
      "  [ 0.9931725 ]\n",
      "  [-0.8193571 ]\n",
      "  [ 0.99230236]\n",
      "  [ 0.9406266 ]\n",
      "  [-0.41441104]\n",
      "  [ 0.6689785 ]\n",
      "  [ 0.9132295 ]\n",
      "  [-0.6366158 ]\n",
      "  [ 0.15170914]\n",
      "  [ 0.40165803]\n",
      "  [ 0.16117589]\n",
      "  [-0.5106815 ]\n",
      "  [ 0.362984  ]\n",
      "  [ 0.54553926]\n",
      "  [ 0.447283  ]\n",
      "  [ 0.95380676]\n",
      "  [-0.8593017 ]\n",
      "  [ 0.99192345]\n",
      "  [ 0.9754672 ]\n",
      "  [-0.7641042 ]\n",
      "  [ 0.6613829 ]\n",
      "  [ 0.49865323]]]\n",
      "['5.10', '5.11', '4.5.10', '4.9', 'G#3', '0.3', 'C#6', '10.0.3', 'G#6', 'D5', '0.1', 'G3', '11.4', 'C4', '0', '2.6.7', 'A4', '0.6', 'F5', '0.1', 'F3', 'E2', 'G#3', 'G4', 'G6', 'G#3', '10.1.3', '6.9', 'E3', '2.4', 'D5', '1.4', '4.6', '2.3.7.10', '0.2.5', 'G#6', '10.0.3', '10.1.5', '10.0.3', '5.7', '11.4', '1.4', '0.3.5', '5.9.0', 'B-4', 'E-2', 'G3', '0.3.6', 'G3', 'G#6', 'G6', '10.1.4', '0.3.6', '0.5', '0.2.6', '1', '2.3.7.10', '2.4', '6', 'E-2', 'G6', '4.10', 'C#4', 'C7', 'E5', '11.2.5', '8.11', '10.1', '2.6', '0.1', '0.3.5', '1.7', 'G4', 'F#5', '1.3', '6.9', '0.2', '2.4', 'G6', '1.3.5', 'G6', 'G#5', '2.8', 'C6', 'G#2', '10.2', '7.8', '9.10.2', '7.8.0', '11.3', '9.1', 'B2', 'A1', 'G#6', '1', 'G6', 'G4', '1.5.8', 'C5', 'B-2']\n",
      "../output/GAN_1570437586/GAN_output_1\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_100.hdf5\n",
      "[[[ 0.9177584 ]\n",
      "  [ 0.98738796]\n",
      "  [-0.83107287]\n",
      "  [ 0.9699626 ]\n",
      "  [-0.42094788]\n",
      "  [ 0.2818631 ]\n",
      "  [ 0.9873179 ]\n",
      "  [ 0.9797492 ]\n",
      "  [ 0.35794145]\n",
      "  [ 0.9930144 ]\n",
      "  [ 0.98555475]\n",
      "  [ 0.9285567 ]\n",
      "  [ 0.9583052 ]\n",
      "  [ 0.9462652 ]\n",
      "  [ 0.98849505]\n",
      "  [ 0.9943257 ]\n",
      "  [ 0.9910189 ]\n",
      "  [ 0.92344207]\n",
      "  [-0.30631208]\n",
      "  [ 0.5470036 ]\n",
      "  [ 0.4706545 ]\n",
      "  [-0.9789036 ]\n",
      "  [ 0.9291326 ]\n",
      "  [ 0.96112734]\n",
      "  [ 0.98058265]\n",
      "  [ 0.82296604]\n",
      "  [ 0.14160575]\n",
      "  [ 0.9665765 ]\n",
      "  [ 0.4740766 ]\n",
      "  [ 0.9904166 ]\n",
      "  [ 0.98172534]\n",
      "  [-0.22065605]\n",
      "  [-0.5130706 ]\n",
      "  [ 0.95884204]\n",
      "  [ 0.41232085]\n",
      "  [-0.8703504 ]\n",
      "  [ 0.9711525 ]\n",
      "  [ 0.6324574 ]\n",
      "  [ 0.9937818 ]\n",
      "  [ 0.6821486 ]\n",
      "  [ 0.935777  ]\n",
      "  [ 0.9989743 ]\n",
      "  [-0.06527809]\n",
      "  [ 0.292823  ]\n",
      "  [ 0.86166775]\n",
      "  [-0.99500054]\n",
      "  [-0.30968693]\n",
      "  [-0.4947066 ]\n",
      "  [-0.64786077]\n",
      "  [ 0.3045548 ]\n",
      "  [ 0.9787167 ]\n",
      "  [ 0.8751803 ]\n",
      "  [-0.5597309 ]\n",
      "  [ 0.9238583 ]\n",
      "  [ 0.48372978]\n",
      "  [ 0.79548824]\n",
      "  [ 0.9069592 ]\n",
      "  [-0.8590328 ]\n",
      "  [ 0.8533415 ]\n",
      "  [ 0.7824838 ]\n",
      "  [ 0.23058605]\n",
      "  [-0.14135908]\n",
      "  [ 0.88287   ]\n",
      "  [-0.9990006 ]\n",
      "  [-0.12574531]\n",
      "  [ 0.04804595]\n",
      "  [ 0.98837864]\n",
      "  [ 0.9885043 ]\n",
      "  [ 0.9156647 ]\n",
      "  [ 0.28160346]\n",
      "  [ 0.09700432]\n",
      "  [ 0.9605348 ]\n",
      "  [-0.8732221 ]\n",
      "  [-0.77973557]\n",
      "  [ 0.9165534 ]\n",
      "  [-0.96502525]\n",
      "  [-0.95302117]\n",
      "  [ 0.61562   ]\n",
      "  [-0.7742344 ]\n",
      "  [-0.92271125]\n",
      "  [-0.9479271 ]\n",
      "  [-0.9712577 ]\n",
      "  [ 0.79833055]\n",
      "  [-0.9788755 ]\n",
      "  [-0.25802234]\n",
      "  [ 0.80986035]\n",
      "  [-0.9000853 ]\n",
      "  [-0.99522066]\n",
      "  [-0.58067775]\n",
      "  [ 0.029958  ]\n",
      "  [-0.9969505 ]\n",
      "  [-0.91882414]\n",
      "  [-0.99506086]\n",
      "  [-0.99836916]\n",
      "  [-0.99995846]\n",
      "  [-0.9901469 ]\n",
      "  [-0.9977203 ]\n",
      "  [-0.97254825]\n",
      "  [-0.9985599 ]\n",
      "  [-0.9897206 ]]]\n",
      "['G#2', 'G5', '1.3', 'G3', '2.7', '8.9', 'G5', 'G4', '9.0.4', 'G6', 'G5', 'G#4', 'G2', 'G#6', 'G5', 'G6', 'G6', 'G#3', '3.6.10', 'B2', 'A4', '0.2', 'G#4', 'G2', 'G4', 'F#2', '7.11.2', 'G3', 'A4', 'G5', 'G4', '4.6', '11.3', 'G2', '9.11', '0.6', 'G3', 'C2', 'G6', 'C7', 'G#4', 'G6', '5.8.0', '8.9.0', 'F#6', '0', '3.6.10', '2', '10.11.3', '9', 'G4', 'F3', '11.1.2', 'G#3', 'A5', 'E4', 'F6', '1', 'F#5', 'E2', '8.1', '5', 'F3', '0', '5.11', '6.8.10', 'G5', 'G5', 'G#2', '8.9', '7.0', 'G2', '0.6', '1.5', 'G#2', '0.2.5', '0.2.7', 'C#6', '1.5.6', '0.3.5.8', '0.2.7', '0.2.5', 'E4', '0.2', '4', 'E5', '0.4', '0', '11.0.4', '6.7.11', '0', '0.3.6', '0', '0', '0', '0.1', '0', '0.2.5', '0', '0.1']\n",
      "../output/GAN_1570437586/GAN_output_2\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_20.hdf5\n",
      "[[[ 9.9490863e-01]\n",
      "  [ 5.3547657e-01]\n",
      "  [-2.6077369e-01]\n",
      "  [-9.9613142e-01]\n",
      "  [-5.5877411e-01]\n",
      "  [ 3.0699551e-01]\n",
      "  [-1.5853995e-01]\n",
      "  [-9.9775720e-01]\n",
      "  [-1.9040088e-01]\n",
      "  [-9.9705672e-01]\n",
      "  [ 5.9861016e-01]\n",
      "  [-9.8701991e-02]\n",
      "  [-6.8717420e-01]\n",
      "  [-9.5344400e-01]\n",
      "  [-4.9545169e-01]\n",
      "  [ 5.0390339e-01]\n",
      "  [ 7.9112089e-01]\n",
      "  [-9.8952037e-01]\n",
      "  [-9.9033445e-01]\n",
      "  [-4.0142515e-01]\n",
      "  [-1.5375124e-01]\n",
      "  [-9.3100178e-01]\n",
      "  [ 5.0233191e-01]\n",
      "  [ 3.4991327e-01]\n",
      "  [ 8.8850605e-01]\n",
      "  [ 1.8395239e-01]\n",
      "  [-6.0373175e-01]\n",
      "  [ 9.4441092e-01]\n",
      "  [-5.1297206e-01]\n",
      "  [ 7.6182503e-01]\n",
      "  [-9.6660757e-01]\n",
      "  [-1.3718262e-01]\n",
      "  [-7.9340446e-01]\n",
      "  [-2.8189686e-01]\n",
      "  [ 9.2598420e-01]\n",
      "  [-8.2426924e-01]\n",
      "  [ 7.2069967e-01]\n",
      "  [-7.9137802e-01]\n",
      "  [ 8.2131457e-01]\n",
      "  [-4.2040268e-01]\n",
      "  [-9.2707306e-01]\n",
      "  [-9.8120403e-01]\n",
      "  [-7.1508491e-01]\n",
      "  [-9.4488800e-01]\n",
      "  [-9.7246051e-01]\n",
      "  [ 9.9893665e-01]\n",
      "  [-6.2403202e-01]\n",
      "  [-7.5388676e-01]\n",
      "  [ 4.9878466e-01]\n",
      "  [-9.7443914e-01]\n",
      "  [-8.5591096e-01]\n",
      "  [-8.6312693e-01]\n",
      "  [-9.8360896e-01]\n",
      "  [ 7.0613754e-01]\n",
      "  [-8.3831626e-01]\n",
      "  [-8.1719065e-01]\n",
      "  [ 1.2964444e-01]\n",
      "  [ 8.3744007e-01]\n",
      "  [ 5.9942949e-01]\n",
      "  [ 3.4908068e-01]\n",
      "  [-4.5248163e-01]\n",
      "  [-5.6361037e-01]\n",
      "  [ 9.8611546e-01]\n",
      "  [ 2.3789984e-01]\n",
      "  [-7.5003803e-01]\n",
      "  [ 9.5884019e-01]\n",
      "  [-2.6962185e-01]\n",
      "  [-4.5573956e-01]\n",
      "  [-1.2314196e-01]\n",
      "  [-6.6605496e-01]\n",
      "  [-7.5243282e-01]\n",
      "  [ 9.7239465e-01]\n",
      "  [-1.8372081e-01]\n",
      "  [-3.1341672e-01]\n",
      "  [-2.2495064e-01]\n",
      "  [-3.7917692e-02]\n",
      "  [ 9.9351233e-01]\n",
      "  [-6.6292083e-01]\n",
      "  [-4.8457363e-04]\n",
      "  [-1.3050067e-01]\n",
      "  [ 8.7631387e-01]\n",
      "  [ 9.9654543e-01]\n",
      "  [-9.2150563e-01]\n",
      "  [-7.4853218e-01]\n",
      "  [ 5.7989335e-01]\n",
      "  [-9.7658706e-01]\n",
      "  [ 2.9689589e-01]\n",
      "  [-1.4731047e-01]\n",
      "  [ 9.9857831e-01]\n",
      "  [ 1.1545242e-01]\n",
      "  [ 7.0443347e-02]\n",
      "  [-7.9035455e-01]\n",
      "  [ 9.9942529e-01]\n",
      "  [-6.4803410e-01]\n",
      "  [ 8.1959665e-01]\n",
      "  [-5.1391041e-01]\n",
      "  [ 8.8995939e-01]\n",
      "  [ 2.8540871e-01]\n",
      "  [-2.1843529e-01]\n",
      "  [ 6.9503462e-01]]]\n",
      "['G6', 'B-6', '4', '0', '11.1.2', '9.0', '4.8.9', '0', '4.7', '0', 'C#4', '5.7.10.0', '10.1', '0.2.7', '2', 'B-2', 'E3', '0.1', '0.1', '3', '4.8.9', '0.3.5', 'B-2', '9.0.3.5', 'F4', '7.9.11', '10.3', 'G#5', '11.3', 'E-5', '0.2.5', '5', '1.3.8', '3.8', 'G#3', '1.3.4', 'D5', '1.4', 'F#2', '2.7', '0.3.5.8', '0.2', '10.0.1', '0.3', '0.2.5', 'G6', '10.2.3', '1.6', 'B-2', '0.2', '1', '1', '0.1', 'D4', '1.2.4', '1.3.5', '7.11', 'F#3', 'C#4', '9.0.3.5', '2.5', '11.1.2', 'G5', '8.10', '1.6', 'G2', '3.9', '2.5', '5.11', '10.1.4', '1.6', 'G3', '4.7.9', '3.6.10', '4.6', '5.9.0', 'G6', '10.1.4', '6.11', '5.10', 'F3', 'G6', '0.3.5.8', '1.6', 'C#2', '0.2', '8.9.0', '4.9', 'G6', '7.10.0', '6.9.1', '1.4', 'G6', '10.11.3', 'E6', '11.2.5', 'F4', '8.9', '4.6', 'D3']\n",
      "../output/GAN_1570437586/GAN_output_3\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_30.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.31863266]\n",
      "  [-0.04901373]\n",
      "  [ 0.9647185 ]\n",
      "  [-0.9970886 ]\n",
      "  [-0.7901506 ]\n",
      "  [-0.5245192 ]\n",
      "  [-0.99598765]\n",
      "  [-0.98946106]\n",
      "  [-0.97796994]\n",
      "  [-0.7766503 ]\n",
      "  [-0.9589379 ]\n",
      "  [-0.90780485]\n",
      "  [-0.89653635]\n",
      "  [-0.83506596]\n",
      "  [-0.9946219 ]\n",
      "  [-0.698596  ]\n",
      "  [ 0.70834357]\n",
      "  [ 0.33375612]\n",
      "  [-0.83358085]\n",
      "  [-0.9176603 ]\n",
      "  [-0.88028145]\n",
      "  [-0.8599078 ]\n",
      "  [ 0.9162866 ]\n",
      "  [ 0.13114238]\n",
      "  [-0.6726755 ]\n",
      "  [-0.8211164 ]\n",
      "  [-0.46654317]\n",
      "  [ 0.22901817]\n",
      "  [-0.96735495]\n",
      "  [-0.28233814]\n",
      "  [ 0.6000631 ]\n",
      "  [ 0.6072935 ]\n",
      "  [ 0.7140057 ]\n",
      "  [ 0.82475835]\n",
      "  [-0.14915876]\n",
      "  [-0.96274424]\n",
      "  [ 0.8794212 ]\n",
      "  [-0.44175673]\n",
      "  [ 0.39304227]\n",
      "  [ 0.7064495 ]\n",
      "  [-0.8201694 ]\n",
      "  [ 0.12927328]\n",
      "  [-0.85720026]\n",
      "  [ 0.00342063]\n",
      "  [ 0.10993685]\n",
      "  [ 0.8549226 ]\n",
      "  [-0.8549247 ]\n",
      "  [-0.9479352 ]\n",
      "  [-0.92161894]\n",
      "  [-0.8428619 ]\n",
      "  [ 0.01836698]\n",
      "  [ 0.88301367]\n",
      "  [ 0.4289415 ]\n",
      "  [-0.65191066]\n",
      "  [ 0.9797393 ]\n",
      "  [ 0.300754  ]\n",
      "  [-0.27318373]\n",
      "  [-0.23616558]\n",
      "  [ 0.92543495]\n",
      "  [-0.91959906]\n",
      "  [ 0.1948324 ]\n",
      "  [ 0.7325499 ]\n",
      "  [ 0.9932095 ]\n",
      "  [ 0.62463814]\n",
      "  [ 0.13960676]\n",
      "  [-0.79499537]\n",
      "  [ 0.9946575 ]\n",
      "  [ 0.25026834]\n",
      "  [ 0.896672  ]\n",
      "  [-0.14552738]\n",
      "  [-0.71430314]\n",
      "  [ 0.97353613]\n",
      "  [ 0.44499236]\n",
      "  [-0.58300054]\n",
      "  [-0.98714256]\n",
      "  [-0.27650973]\n",
      "  [ 0.28051153]\n",
      "  [-0.93496543]\n",
      "  [ 0.9703624 ]\n",
      "  [ 0.80432993]\n",
      "  [ 0.9977876 ]\n",
      "  [-0.34665865]\n",
      "  [-0.97240645]\n",
      "  [-0.53604156]\n",
      "  [-0.18358514]\n",
      "  [ 0.95097053]\n",
      "  [ 0.24664745]\n",
      "  [ 0.98401284]\n",
      "  [ 0.7086993 ]\n",
      "  [ 0.98232085]\n",
      "  [ 0.9716037 ]\n",
      "  [ 0.9946    ]\n",
      "  [ 0.97874266]\n",
      "  [ 0.9756703 ]\n",
      "  [ 0.99674296]\n",
      "  [ 0.98874325]\n",
      "  [ 0.9995389 ]\n",
      "  [ 0.987653  ]\n",
      "  [ 0.8443001 ]\n",
      "  [ 0.2813664 ]]]\n",
      "['3.6', '5.9', 'G3', '0', '1.4', '11.2.4', '0', '0.1', '0.2', '1.5', '0.2.6', '0.3.7', '0.4', '1.3', '0', '10.0.3', 'D4', '9.0.3', '1.3', '0.3.6', '0.5', '1', 'G#2', '7.11', '10.1.3', '1.3.4', '2.4', '8.1', '0.2.5', '3.8', 'C#4', 'C#5', 'D5', 'F#2', '4.9', '0.2.6', 'F3', '2.6', '9.10.1.3.5', 'D4', '1.3.4', '7.11', '1', '6.11.0', '7.10.0', 'F#5', '1.2', '0.2.7', '0.3.5.8', '1.2.4', '6.7.10.11.2', 'F4', '9.11.2', '10.1.5', 'G4', '9', '3.8.9', '4.5', 'G#3', '0.3.5.8', '8', 'E-2', 'G6', 'C#7', '7.11.2', '1.3.8', 'G6', '8.10.1', 'F5', '4.9', '10.0.1', 'G4', 'A1', '11.0.4', '0.1', '3.8.9', '8.9', '0.3.5', 'G3', 'E5', 'G6', '3.5.7.8', '0.2.5', '11.2', '4.7.9', 'G#6', '8.10.1', 'G5', 'D4', 'G5', 'G3', 'G6', 'G4', 'G4', 'G6', 'G5', 'G6', 'G5', 'F#4', '8.9']\n",
      "../output/GAN_1570437586/GAN_output_4\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_40.hdf5\n",
      "[[[-0.25871775]\n",
      "  [-0.994915  ]\n",
      "  [-0.9915166 ]\n",
      "  [-0.9987217 ]\n",
      "  [-0.99779356]\n",
      "  [-0.9970581 ]\n",
      "  [-0.80087143]\n",
      "  [-0.99897933]\n",
      "  [-0.8784297 ]\n",
      "  [-0.48795527]\n",
      "  [-0.8439413 ]\n",
      "  [-0.89232814]\n",
      "  [-0.9836261 ]\n",
      "  [-0.42060626]\n",
      "  [-0.98705816]\n",
      "  [-0.9927525 ]\n",
      "  [-0.97481954]\n",
      "  [-0.7947968 ]\n",
      "  [ 0.92293745]\n",
      "  [ 0.18478553]\n",
      "  [-0.98377454]\n",
      "  [-0.5882095 ]\n",
      "  [-0.95874494]\n",
      "  [-0.08742324]\n",
      "  [-0.91133535]\n",
      "  [ 0.95000434]\n",
      "  [-0.12692288]\n",
      "  [-0.97894263]\n",
      "  [-0.64742386]\n",
      "  [-0.98874944]\n",
      "  [-0.96578944]\n",
      "  [-0.9971053 ]\n",
      "  [-0.9925335 ]\n",
      "  [-0.6723653 ]\n",
      "  [ 0.28507638]\n",
      "  [ 0.9553405 ]\n",
      "  [ 0.46907496]\n",
      "  [-0.9486088 ]\n",
      "  [-0.556528  ]\n",
      "  [ 0.15574701]\n",
      "  [-0.9507248 ]\n",
      "  [-0.6500537 ]\n",
      "  [-0.42622674]\n",
      "  [ 0.99621135]\n",
      "  [ 0.89593524]\n",
      "  [ 0.7333449 ]\n",
      "  [-0.116673  ]\n",
      "  [ 0.9762775 ]\n",
      "  [ 0.66938496]\n",
      "  [-0.23989378]\n",
      "  [-0.9378599 ]\n",
      "  [ 0.9484008 ]\n",
      "  [-0.24772549]\n",
      "  [-0.10649749]\n",
      "  [ 0.8300628 ]\n",
      "  [-0.9714086 ]\n",
      "  [ 0.8357071 ]\n",
      "  [-0.76356965]\n",
      "  [-0.83797795]\n",
      "  [-0.6202604 ]\n",
      "  [-0.95200944]\n",
      "  [-0.4529548 ]\n",
      "  [-0.7857578 ]\n",
      "  [-0.9362999 ]\n",
      "  [ 0.4132909 ]\n",
      "  [ 0.971808  ]\n",
      "  [ 0.7080036 ]\n",
      "  [-0.9996875 ]\n",
      "  [-0.2348832 ]\n",
      "  [-0.9743688 ]\n",
      "  [-0.8958888 ]\n",
      "  [-0.9618264 ]\n",
      "  [ 0.8317341 ]\n",
      "  [ 0.8044846 ]\n",
      "  [ 0.8023458 ]\n",
      "  [ 0.9575151 ]\n",
      "  [ 0.9907998 ]\n",
      "  [ 0.99035466]\n",
      "  [ 0.98275113]\n",
      "  [ 0.8146977 ]\n",
      "  [ 0.99997705]\n",
      "  [ 0.99732506]\n",
      "  [ 0.99637604]\n",
      "  [ 0.9987584 ]\n",
      "  [ 0.8706739 ]\n",
      "  [ 0.9986788 ]\n",
      "  [ 0.99965405]\n",
      "  [ 0.99954146]\n",
      "  [ 0.9563731 ]\n",
      "  [ 0.9990369 ]\n",
      "  [ 0.9998075 ]\n",
      "  [ 0.99683166]\n",
      "  [ 0.99686426]\n",
      "  [ 0.9455398 ]\n",
      "  [ 0.99900854]\n",
      "  [ 0.9805844 ]\n",
      "  [ 0.99928576]\n",
      "  [ 0.9983697 ]\n",
      "  [ 0.9217186 ]\n",
      "  [ 0.98023635]]]\n",
      "['4', '0', '0', '0', '0', '0', '1.3.8', '0', '0.5', '2', '1.2.4', '0.4', '0.1', '2.7', '0.1', '0', '0.2', '1.3.8', 'G#3', '7.9.11', '0.1', '11.0', '0.2.6', '5.7.11', '0.3.6', 'G#6', '5.10', '0.2', '10.11.3', '0.1', '0.2.5', '0', '0', '10.1.3', '8.9', 'G2', 'A4', '0.2.7', '11.1.4', '7.8.0', '0.2.7', '10.1.5', '2.6.9', 'G6', 'F5', 'E-2', '5.6', 'G4', 'C6', '4.5', '0.3', 'G#6', '4.10', '5.7', 'F#3', '0.2.5', 'F#3', '1.5.8', '1.2.4', '10.2.5', '0.2.7', '2.5', '1.4', '0.3.5', '9.11', 'G3', 'D4', '0', '4.5', '0.2', '0.4', '0.2.6', 'F#3', 'E5', 'E5', 'G2', 'G5', 'G5', 'G5', 'E6', 'G6', 'G6', 'G6', 'G6', 'F2', 'G6', 'G6', 'G6', 'G2', 'G6', 'G6', 'G6', 'G6', 'G#5', 'G6', 'G4', 'G6', 'G6', 'G#3', 'G4']\n",
      "../output/GAN_1570437586/GAN_output_5\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_50.hdf5\n",
      "[[[ 0.6521778 ]\n",
      "  [ 0.93266606]\n",
      "  [ 0.42853844]\n",
      "  [ 0.8221318 ]\n",
      "  [ 0.611681  ]\n",
      "  [ 0.44760257]\n",
      "  [-0.2894374 ]\n",
      "  [-0.85770565]\n",
      "  [-0.9383569 ]\n",
      "  [ 0.70101094]\n",
      "  [-0.8648488 ]\n",
      "  [-0.02099649]\n",
      "  [-0.17508054]\n",
      "  [-0.99447805]\n",
      "  [-0.6308417 ]\n",
      "  [-0.7619271 ]\n",
      "  [-0.73954535]\n",
      "  [-0.93769854]\n",
      "  [-0.34499204]\n",
      "  [-0.8109995 ]\n",
      "  [ 0.33451375]\n",
      "  [-0.3299262 ]\n",
      "  [-0.9176867 ]\n",
      "  [-0.800101  ]\n",
      "  [-0.7269434 ]\n",
      "  [-0.9860674 ]\n",
      "  [ 0.84098727]\n",
      "  [ 0.03406249]\n",
      "  [-0.70514834]\n",
      "  [ 0.09472818]\n",
      "  [-0.9857671 ]\n",
      "  [-0.7681661 ]\n",
      "  [ 0.76186764]\n",
      "  [-0.5229782 ]\n",
      "  [-0.73896396]\n",
      "  [-0.8807165 ]\n",
      "  [-0.46248782]\n",
      "  [-0.9467175 ]\n",
      "  [-0.7925683 ]\n",
      "  [-0.02473838]\n",
      "  [-0.8247522 ]\n",
      "  [-0.9113923 ]\n",
      "  [ 0.33257365]\n",
      "  [ 0.2979081 ]\n",
      "  [-0.07393506]\n",
      "  [-0.9078593 ]\n",
      "  [-0.27735707]\n",
      "  [-0.9554468 ]\n",
      "  [-0.93261445]\n",
      "  [-0.81191   ]\n",
      "  [ 0.4673124 ]\n",
      "  [ 0.0364304 ]\n",
      "  [ 0.4570423 ]\n",
      "  [ 0.34271225]\n",
      "  [-0.09101979]\n",
      "  [-0.22852814]\n",
      "  [ 0.32869324]\n",
      "  [ 0.6927553 ]\n",
      "  [-0.35614958]\n",
      "  [ 0.4846862 ]\n",
      "  [-0.81093794]\n",
      "  [ 0.3930082 ]\n",
      "  [ 0.9393101 ]\n",
      "  [ 0.6214834 ]\n",
      "  [ 0.9083683 ]\n",
      "  [ 0.83636975]\n",
      "  [ 0.7914451 ]\n",
      "  [ 0.9417334 ]\n",
      "  [ 0.87189955]\n",
      "  [ 0.8340379 ]\n",
      "  [ 0.15242237]\n",
      "  [ 0.9104353 ]\n",
      "  [ 0.63133466]\n",
      "  [ 0.9862772 ]\n",
      "  [ 0.98037845]\n",
      "  [ 0.9899284 ]\n",
      "  [ 0.81149566]\n",
      "  [ 0.8029941 ]\n",
      "  [ 0.7962291 ]\n",
      "  [ 0.99136466]\n",
      "  [ 0.9793858 ]\n",
      "  [ 0.8737785 ]\n",
      "  [ 0.65263975]\n",
      "  [ 0.9440469 ]\n",
      "  [ 0.97855353]\n",
      "  [ 0.8070216 ]\n",
      "  [ 0.98712534]\n",
      "  [ 0.9994517 ]\n",
      "  [ 0.8982265 ]\n",
      "  [ 0.9976942 ]\n",
      "  [ 0.99365413]\n",
      "  [ 0.9982312 ]\n",
      "  [ 0.82602936]\n",
      "  [ 0.89444125]\n",
      "  [ 0.7824592 ]\n",
      "  [ 0.5967721 ]\n",
      "  [ 0.9015084 ]\n",
      "  [ 0.523906  ]\n",
      "  [ 0.6111528 ]\n",
      "  [ 0.45247293]]]\n",
      "['C4', 'G#4', '9.11.2', 'F#2', 'C#5', 'A1', '3.7.10', '1', '0.3', 'D3', '1', '6.10', '4.8', '0', '10.2', '1.5.8', '1.7', '0.3', '3.5.7.8', '1.3.5', '9.0.3', '3.5.9', '0.3.6', '1.3.8', '10.0', '0.1', 'F#4', '6.7.11', '10.0.2', '7.0', '0.1', '1.5.6', 'E-5', '11.2.4', '1.7', '0.5', '2.4', '0.2.7', '1.4', '6.10', '1.3.4', '0.3.6', '9.0.2', '9', '5.8', '0.3.7', '3.8.9', '0.2.6', '0.3.5', '1.3.5', 'A3', '6.8', 'A2', '9.0.3.5', '5.7.10.0', '4.5.10', '9.0.2', 'D2', '3.5.7', 'A5', '1.3.5', '9.10.1.3.5', 'G#5', 'C#6', 'F6', 'F#3', 'E3', 'G#5', 'F2', 'F#3', '7.8', 'G#2', 'C2', 'G5', 'G4', 'G5', 'E6', 'E5', 'E4', 'G6', 'G4', 'F2', 'C4', 'G#5', 'G4', 'E5', 'G5', 'G6', 'F5', 'G6', 'G6', 'G6', 'F#2', 'F5', 'E2', 'C#4', 'F6', 'B-5', 'C#5', 'A2']\n",
      "../output/GAN_1570437586/GAN_output_6\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_60.hdf5\n",
      "[[[ 0.06400237]\n",
      "  [-0.54032683]\n",
      "  [ 0.2836312 ]\n",
      "  [-0.9929889 ]\n",
      "  [ 0.9553547 ]\n",
      "  [-0.5616267 ]\n",
      "  [ 0.02100052]\n",
      "  [-0.28586817]\n",
      "  [-0.5546038 ]\n",
      "  [-0.52347714]\n",
      "  [-0.7036747 ]\n",
      "  [-0.980614  ]\n",
      "  [-0.9834632 ]\n",
      "  [-0.8711916 ]\n",
      "  [-0.9954827 ]\n",
      "  [-0.99023044]\n",
      "  [-0.9991931 ]\n",
      "  [-0.96848553]\n",
      "  [ 0.552524  ]\n",
      "  [-0.3814908 ]\n",
      "  [-0.1997294 ]\n",
      "  [ 0.7372391 ]\n",
      "  [-0.76574016]\n",
      "  [ 0.5685519 ]\n",
      "  [-0.31086856]\n",
      "  [-0.708972  ]\n",
      "  [-0.67218673]\n",
      "  [-0.860819  ]\n",
      "  [ 0.33719745]\n",
      "  [-0.7321856 ]\n",
      "  [-0.73941547]\n",
      "  [-0.717914  ]\n",
      "  [-0.45786312]\n",
      "  [ 0.21894892]\n",
      "  [-0.41100088]\n",
      "  [ 0.56389165]\n",
      "  [ 0.35289845]\n",
      "  [ 0.7444856 ]\n",
      "  [ 0.61666286]\n",
      "  [-0.9961044 ]\n",
      "  [ 0.37427965]\n",
      "  [-0.9086951 ]\n",
      "  [-0.9294857 ]\n",
      "  [-0.67904603]\n",
      "  [-0.72147965]\n",
      "  [-0.04234914]\n",
      "  [ 0.28840068]\n",
      "  [ 0.8346564 ]\n",
      "  [-0.6384258 ]\n",
      "  [-0.23214698]\n",
      "  [-0.87720615]\n",
      "  [ 0.6585557 ]\n",
      "  [ 0.9513092 ]\n",
      "  [-0.869783  ]\n",
      "  [-0.21023409]\n",
      "  [ 0.8666181 ]\n",
      "  [-0.83542114]\n",
      "  [-0.4682108 ]\n",
      "  [-0.9498563 ]\n",
      "  [ 0.67520404]\n",
      "  [ 0.68191284]\n",
      "  [ 0.89439213]\n",
      "  [ 0.96623635]\n",
      "  [ 0.9011037 ]\n",
      "  [ 0.73239225]\n",
      "  [ 0.99945176]\n",
      "  [-0.66615283]\n",
      "  [-0.7070848 ]\n",
      "  [ 0.95228285]\n",
      "  [ 0.03956267]\n",
      "  [ 0.92843014]\n",
      "  [ 0.6454415 ]\n",
      "  [ 0.78294456]\n",
      "  [ 0.9905215 ]\n",
      "  [ 0.93812644]\n",
      "  [ 0.6472285 ]\n",
      "  [ 0.9994339 ]\n",
      "  [ 0.97485584]\n",
      "  [ 0.6525602 ]\n",
      "  [ 0.9098285 ]\n",
      "  [ 0.9999054 ]\n",
      "  [ 0.9291829 ]\n",
      "  [ 0.8131242 ]\n",
      "  [ 0.9776415 ]\n",
      "  [ 0.9484834 ]\n",
      "  [ 0.84433895]\n",
      "  [ 0.86937916]\n",
      "  [ 0.99703056]\n",
      "  [ 0.9862617 ]\n",
      "  [ 0.98963183]\n",
      "  [ 0.9991889 ]\n",
      "  [ 0.9998129 ]\n",
      "  [ 0.9999252 ]\n",
      "  [ 0.99462855]\n",
      "  [ 0.9993198 ]\n",
      "  [ 0.9976224 ]\n",
      "  [ 0.99727106]\n",
      "  [ 0.9870587 ]\n",
      "  [ 0.99945104]\n",
      "  [ 0.9583654 ]]]\n",
      "['6.9.1', '11.2', '8.9', '0', 'G2', '11.1.2', '6.7.10.11.2', '3.8', '11.1.4', '11.2.4', '10.0.2', '0.2', '0.1', '0.6', '0', '0.1', '0', '0.2.5', 'B3', '3.4.6', '4.6.7', 'E-2', '1.5.8', 'B5', '3.6.10', '10.0.2', '10.1.3', '1', '9.0.3', '10', '1.7', '10.0.1', '2.5', '8.0.3', '2.8', 'B4', '9.0.4', 'E-3', 'C#6', '0', '9.1.4', '0.3.7', '0.3.5', '10.1.2.5', '10.0', '5.9.0', '8.9.0', 'F#3', '10.2', '4.5.10', '0.5', 'C5', 'G#6', '0.6', '4.6.11', 'F2', '1.3', '2.4', '0.2.7', 'C6', 'C7', 'F5', 'G3', 'F6', 'E-2', 'G6', '10.1.4', '10.0.2', 'G#6', '6.8', 'G#4', 'C3', 'E2', 'G5', 'G#5', 'C3', 'G6', 'G4', 'C4', 'F6', 'G6', 'G#4', 'E6', 'G4', 'G#6', 'F#4', 'F2', 'G6', 'G5', 'G5', 'G6', 'G6', 'G6', 'G6', 'G6', 'G6', 'G6', 'G5', 'G6', 'G2']\n",
      "../output/GAN_1570437586/GAN_output_7\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_70.hdf5\n",
      "[[[ 0.84865177]\n",
      "  [ 0.9956309 ]\n",
      "  [ 0.9842493 ]\n",
      "  [ 0.99979174]\n",
      "  [ 0.98771787]\n",
      "  [ 0.96267337]\n",
      "  [ 0.9757762 ]\n",
      "  [ 0.9992097 ]\n",
      "  [ 0.99319214]\n",
      "  [ 0.9871718 ]\n",
      "  [ 0.9990751 ]\n",
      "  [ 0.98510814]\n",
      "  [ 0.99941385]\n",
      "  [ 0.9968607 ]\n",
      "  [ 0.9997136 ]\n",
      "  [ 0.9147155 ]\n",
      "  [ 0.98842466]\n",
      "  [ 0.9999631 ]\n",
      "  [ 0.89281124]\n",
      "  [ 0.999156  ]\n",
      "  [-0.7897301 ]\n",
      "  [ 0.59107924]\n",
      "  [ 0.8856362 ]\n",
      "  [ 0.95329404]\n",
      "  [ 0.9964645 ]\n",
      "  [-0.14430277]\n",
      "  [ 0.9187659 ]\n",
      "  [ 0.9944368 ]\n",
      "  [ 0.7683285 ]\n",
      "  [ 0.72669834]\n",
      "  [ 0.90813255]\n",
      "  [ 0.8267961 ]\n",
      "  [ 0.59239745]\n",
      "  [ 0.6301626 ]\n",
      "  [ 0.9926954 ]\n",
      "  [ 0.9945566 ]\n",
      "  [ 0.84632766]\n",
      "  [ 0.9987059 ]\n",
      "  [ 0.938807  ]\n",
      "  [ 0.8766112 ]\n",
      "  [ 0.59070396]\n",
      "  [ 0.9680438 ]\n",
      "  [-0.46900016]\n",
      "  [-0.97824043]\n",
      "  [ 0.99912006]\n",
      "  [ 0.3775096 ]\n",
      "  [-0.7689996 ]\n",
      "  [ 0.27652913]\n",
      "  [ 0.5491755 ]\n",
      "  [ 0.44946754]\n",
      "  [-0.05416944]\n",
      "  [ 0.9769609 ]\n",
      "  [-0.99947804]\n",
      "  [ 0.60405684]\n",
      "  [ 0.5385134 ]\n",
      "  [ 0.20567867]\n",
      "  [ 0.23495144]\n",
      "  [ 0.96839   ]\n",
      "  [-0.6156937 ]\n",
      "  [ 0.9867281 ]\n",
      "  [-0.97937185]\n",
      "  [-0.43916202]\n",
      "  [ 0.5096326 ]\n",
      "  [-0.9743737 ]\n",
      "  [-0.14490825]\n",
      "  [-0.9638144 ]\n",
      "  [-0.9982621 ]\n",
      "  [ 0.20283367]\n",
      "  [ 0.04192852]\n",
      "  [ 0.7232028 ]\n",
      "  [-0.64988685]\n",
      "  [ 0.15183613]\n",
      "  [-0.23827727]\n",
      "  [-0.9947204 ]\n",
      "  [-0.9130515 ]\n",
      "  [-0.9354279 ]\n",
      "  [-0.9878546 ]\n",
      "  [-0.99863344]\n",
      "  [-0.997169  ]\n",
      "  [-0.9129238 ]\n",
      "  [-0.9764038 ]\n",
      "  [-0.99738705]\n",
      "  [-0.98440564]\n",
      "  [-0.8604981 ]\n",
      "  [-0.9943434 ]\n",
      "  [ 0.01894237]\n",
      "  [-0.94967484]\n",
      "  [-0.9988579 ]\n",
      "  [-0.97995144]\n",
      "  [-0.99986607]\n",
      "  [-0.48524353]\n",
      "  [-0.9203865 ]\n",
      "  [ 0.7928254 ]\n",
      "  [-0.9968147 ]\n",
      "  [-0.94193584]\n",
      "  [-0.9972044 ]\n",
      "  [-0.9978296 ]\n",
      "  [-0.724378  ]\n",
      "  [ 0.27114913]\n",
      "  [-0.9678916 ]]]\n",
      "['F#5', 'G6', 'G5', 'G6', 'G5', 'G2', 'G4', 'G6', 'G6', 'G5', 'G6', 'G5', 'G6', 'G6', 'G6', 'G#2', 'G5', 'G6', 'F5', 'G6', '1.4', 'C#3', 'F4', 'G#6', 'G6', '4.9', 'G#2', 'G6', 'E-6', 'D6', 'F6', 'F#2', 'C#3', 'C#7', 'G6', 'G6', 'F#4', 'G6', 'G#5', 'F3', 'C#3', 'G3', '2.3.7.10', '0.2', 'G6', '9.1.4', '1.5.6', '8.11.2', 'B2', 'A1', '5.8.10', 'G4', '0', 'C#5', 'B-6', '8.0', '8.10', 'G3', '10.2.5', 'G5', '0.2', '2.6.7', 'B-3', '0.2', '4.9', '0.2.6', '0', '8.0', '6.8', 'D6', '10.1.5', '7.8', '4.5', '0', '0.3.6', '0.3.5', '0.1', '0', '0', '0.3.6', '0.2', '0', '0.1', '1', '0', '6.7.10.11.2', '0.2.7', '0', '0.2', '0', '2.3', '0.3.5.8', 'E4', '0', '0.3', '0', '0', '10.0', '8.11.2', '0.2.5']\n",
      "../output/GAN_1570437586/GAN_output_8\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_80.hdf5\n",
      "[[[ 0.50053596]\n",
      "  [-0.9182972 ]\n",
      "  [ 0.15497583]\n",
      "  [-0.9997775 ]\n",
      "  [-0.99797815]\n",
      "  [-0.99931157]\n",
      "  [-0.99999213]\n",
      "  [-0.9999771 ]\n",
      "  [-0.9998344 ]\n",
      "  [-0.999202  ]\n",
      "  [-0.9997568 ]\n",
      "  [-0.99760735]\n",
      "  [-0.9013759 ]\n",
      "  [-0.92914015]\n",
      "  [-0.99918926]\n",
      "  [-0.9929308 ]\n",
      "  [-0.47678483]\n",
      "  [-0.9908147 ]\n",
      "  [-0.9955317 ]\n",
      "  [-0.14272417]\n",
      "  [-0.71613777]\n",
      "  [-0.9935433 ]\n",
      "  [-0.4559967 ]\n",
      "  [-0.6981534 ]\n",
      "  [-0.9823716 ]\n",
      "  [-0.97624147]\n",
      "  [ 0.07514638]\n",
      "  [ 0.05528158]\n",
      "  [ 0.3031974 ]\n",
      "  [-0.9797799 ]\n",
      "  [-0.89159554]\n",
      "  [-0.36618447]\n",
      "  [ 0.19718653]\n",
      "  [-0.9745594 ]\n",
      "  [ 0.12646392]\n",
      "  [ 0.19420661]\n",
      "  [-0.5801196 ]\n",
      "  [-0.89996713]\n",
      "  [-0.714774  ]\n",
      "  [-0.96796346]\n",
      "  [-0.34905726]\n",
      "  [-0.9144176 ]\n",
      "  [ 0.99175954]\n",
      "  [ 0.97420603]\n",
      "  [-0.94290245]\n",
      "  [ 0.84972775]\n",
      "  [-0.97641426]\n",
      "  [-0.3460189 ]\n",
      "  [-0.2505628 ]\n",
      "  [ 0.6954558 ]\n",
      "  [-0.9180455 ]\n",
      "  [-0.9952854 ]\n",
      "  [ 0.98157424]\n",
      "  [-0.19329783]\n",
      "  [-0.4421093 ]\n",
      "  [ 0.96890396]\n",
      "  [ 0.93850374]\n",
      "  [ 0.02998987]\n",
      "  [ 0.39296287]\n",
      "  [-0.9416914 ]\n",
      "  [-0.99970764]\n",
      "  [-0.6701385 ]\n",
      "  [-0.92430305]\n",
      "  [ 0.25849155]\n",
      "  [ 0.429232  ]\n",
      "  [ 0.98308015]\n",
      "  [ 0.9906041 ]\n",
      "  [-0.27143335]\n",
      "  [-0.99645114]\n",
      "  [-0.27900052]\n",
      "  [-0.97678757]\n",
      "  [-0.79196256]\n",
      "  [-0.4715278 ]\n",
      "  [-0.6916517 ]\n",
      "  [-0.8072005 ]\n",
      "  [-0.8595004 ]\n",
      "  [ 0.7877209 ]\n",
      "  [ 0.98998463]\n",
      "  [ 0.38593352]\n",
      "  [ 0.9802263 ]\n",
      "  [ 0.98399085]\n",
      "  [ 0.9226801 ]\n",
      "  [ 0.6040141 ]\n",
      "  [ 0.9955983 ]\n",
      "  [ 0.9997114 ]\n",
      "  [ 0.985873  ]\n",
      "  [ 0.979828  ]\n",
      "  [ 0.99688625]\n",
      "  [ 0.99996984]\n",
      "  [ 0.9998609 ]\n",
      "  [ 0.82723284]\n",
      "  [ 0.992652  ]\n",
      "  [ 0.990615  ]\n",
      "  [ 0.9997215 ]\n",
      "  [ 0.9981329 ]\n",
      "  [ 0.9992768 ]\n",
      "  [ 0.99859333]\n",
      "  [ 0.9963929 ]\n",
      "  [ 0.9991187 ]\n",
      "  [ 0.99545753]]]\n",
      "['B-2', '0.3.6', '7.8.0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0.3.7', '0.3.5', '0', '0', '2.3.7.10', '0.1', '0', '5', '10.0.1', '0', '2.5', '10.0.3', '0.1', '0.2', '6.9.11', '6.9', '9', '0.2', '0.4.7', '3.5.10', '8', '0.2', '7.11', '8', '11.0.4', '0.4', '10.0.1', '0.2.5', '3.5.7.8', '0.3.6', 'G6', 'G4', '0.3', 'F#5', '0.2', '3.5.7.8', '4.10', 'D3', '0.3.6', '0', 'G4', '4.7', '2.6', 'G3', 'G#5', '6.7.11', '9.10.1.3.5', '0.3', '0', '10.1.3', '0.3.5.8', '8.10.3', '9.11.2', 'G5', 'G5', '3.8.9', '0', '3.8.9', '0.2', '1.4', '2.3.7.10', '10.1', '1.3.6', '1', 'E3', 'G5', '9.10', 'G4', 'G5', 'G#3', 'C#5', 'G6', 'G6', 'G5', 'G4', 'G6', 'G6', 'G6', 'F#2', 'G6', 'G5', 'G6', 'G6', 'G6', 'G6', 'G6', 'G6', 'G6']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/GAN_1570437586/GAN_output_9\n",
      "Composing from ../output/GAN_1570437586\\GANmodel_weights_90.hdf5\n",
      "[[[-0.99372005]\n",
      "  [-0.07109336]\n",
      "  [ 0.50417745]\n",
      "  [ 0.6114273 ]\n",
      "  [-0.99372274]\n",
      "  [-0.93069106]\n",
      "  [ 0.14586872]\n",
      "  [-0.9409094 ]\n",
      "  [-0.89703465]\n",
      "  [-0.6764112 ]\n",
      "  [ 0.91217065]\n",
      "  [-0.08329976]\n",
      "  [-0.6026658 ]\n",
      "  [-0.9155475 ]\n",
      "  [-0.4573485 ]\n",
      "  [-0.2710771 ]\n",
      "  [-0.83602333]\n",
      "  [-0.9268878 ]\n",
      "  [ 0.4406684 ]\n",
      "  [ 0.5563792 ]\n",
      "  [ 0.9190806 ]\n",
      "  [-0.56058013]\n",
      "  [ 0.567446  ]\n",
      "  [ 0.8114215 ]\n",
      "  [ 0.8143599 ]\n",
      "  [-0.43429366]\n",
      "  [-0.43725628]\n",
      "  [ 0.1867322 ]\n",
      "  [-0.52914596]\n",
      "  [-0.9893395 ]\n",
      "  [ 0.60228133]\n",
      "  [-0.9499852 ]\n",
      "  [-0.8755273 ]\n",
      "  [ 0.9668063 ]\n",
      "  [-0.04185651]\n",
      "  [-0.33947974]\n",
      "  [ 0.90217185]\n",
      "  [ 0.85657346]\n",
      "  [ 0.14158826]\n",
      "  [-0.539097  ]\n",
      "  [-0.33338523]\n",
      "  [-0.90614957]\n",
      "  [ 0.562485  ]\n",
      "  [ 0.6537802 ]\n",
      "  [ 0.3161599 ]\n",
      "  [ 0.01375579]\n",
      "  [-0.38288748]\n",
      "  [ 0.56375265]\n",
      "  [ 0.90417427]\n",
      "  [ 0.99968565]\n",
      "  [ 0.92991376]\n",
      "  [ 0.87509125]\n",
      "  [ 0.91637343]\n",
      "  [ 0.95765615]\n",
      "  [-0.5329507 ]\n",
      "  [-0.8507352 ]\n",
      "  [ 0.02847389]\n",
      "  [ 0.97127193]\n",
      "  [ 0.9402113 ]\n",
      "  [ 0.6898322 ]\n",
      "  [-0.90896374]\n",
      "  [ 0.96169186]\n",
      "  [ 0.89895463]\n",
      "  [ 0.355919  ]\n",
      "  [ 0.9986625 ]\n",
      "  [ 0.618963  ]\n",
      "  [ 0.9712144 ]\n",
      "  [ 0.46911174]\n",
      "  [ 0.17603572]\n",
      "  [ 0.7575989 ]\n",
      "  [ 0.9361384 ]\n",
      "  [-0.9651585 ]\n",
      "  [ 0.9875792 ]\n",
      "  [ 0.95823777]\n",
      "  [ 0.56523144]\n",
      "  [ 0.90554625]\n",
      "  [-0.7490651 ]\n",
      "  [ 0.31197175]\n",
      "  [ 0.9741825 ]\n",
      "  [ 0.9847881 ]\n",
      "  [ 0.9909746 ]\n",
      "  [ 0.9914861 ]\n",
      "  [ 0.90487057]\n",
      "  [ 0.86972314]\n",
      "  [ 0.7658999 ]\n",
      "  [ 0.6803434 ]\n",
      "  [ 0.88150346]\n",
      "  [ 0.5212705 ]\n",
      "  [ 0.9868538 ]\n",
      "  [ 0.84849006]\n",
      "  [ 0.8455423 ]\n",
      "  [ 0.7091282 ]\n",
      "  [ 0.96740353]\n",
      "  [ 0.9964352 ]\n",
      "  [-0.350721  ]\n",
      "  [ 0.9455173 ]\n",
      "  [ 0.9938847 ]\n",
      "  [ 0.96248764]\n",
      "  [ 0.692428  ]\n",
      "  [ 0.8770077 ]]]\n",
      "['0', '5.8.0', 'B-2', 'C#5', '0', '0.3.5', '7.8', '0.3', '0.4', '10.1.2.5', 'G#2', '5.7.11', '11', '0.3.6', '2.5', '3.8.9', '1.3', '0.3.5.8', '9.2', 'B3', 'G#3', '11.1.2', 'B4', 'E6', 'E6', '2.6.7', '2.6.7', '7.9.11', '11.2.4', '0.1', 'C#4', '0.2.7', '0.5', 'G3', '5.9.0', '3.5.8', 'F6', 'F#6', '7.11.2', '11.2', '3.5.8', '0.3.7', 'B4', 'C4', '9.0.1', '6.7.0', '3.4.6', 'B4', 'F6', 'G6', 'G#4', 'F3', 'G#2', 'G2', '11.2', '1.2', '6.7.11', 'G3', 'G#5', 'D2', '0.3.7', 'G2', 'F5', '9.0.4', 'G6', 'C#6', 'G3', 'A4', '7.9.1', 'E-5', 'G#4', '0.2.5', 'G5', 'G2', 'B4', 'F6', '1.6', '9.0', 'G4', 'G5', 'G5', 'G6', 'F6', 'F2', 'E-6', 'C7', 'F3', 'B-4', 'G5', 'F#5', 'F#4', 'D4', 'G3', 'G6', '3.5.7.8', 'G#5', 'G6', 'G2', 'D2', 'F3']\n",
      "../output/GAN_1570437586/GAN_output_10\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for model_path in glob.glob(gan.outputDest + \"*.hdf5\"):\n",
    "    print(\"Composing from %s\" % model_path)\n",
    "    gan.generator.load_weights(model_path)\n",
    "    prediction_notes = gan.generate_notes(possibleNotes)\n",
    "    gan.create_midi(prediction_notes, gan.outputDest + 'GAN_output_' + str(count))\n",
    "    print(gan.outputDest + 'GAN_output_' + str(count))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Music\n",
    "\n",
    "I will now use the model to generate music by feeding it a random string of notes and have it predict the next one, then have it predict the one after that until a full song has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, notes, network_input, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    pitchnames = sorted(notes)\n",
    "    \n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "#         prediction_input = (prediction_input / float(n_vocab))*2 - 1\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern = np.append(pattern,index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "    print(prediction_output)\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "# prediction_output = generate_notes(model, possibleNotes, network_input, n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will create a midi using these notes and save to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
    "    \n",
    "# create_midi(prediction_output, outputDest + 'LSTM_output_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, I can run this script to convert all of the models into midi files and select my favourite from a much larger album."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have each model make a song\n",
    "count = 0\n",
    "for model_path in glob.glob(outputDest + \"*.hdf5\"):\n",
    "    print(\"Composing from %s\" % model_path)\n",
    "    model.load_weights(model_path)\n",
    "    prediction_output = generate_notes(model, possibleNotes, network_input, n_vocab)\n",
    "    create_midi(prediction_output, outputDest + 'LSTM_output_' + str(count))\n",
    "    print(outputDest + 'LSTM_output_' + str(count))\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
